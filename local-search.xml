<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Redis-多机部署</title>
    <link href="/Redis/Redis-%E5%A4%9A%E6%9C%BA%E9%83%A8%E7%BD%B2.html"/>
    <url>/Redis/Redis-%E5%A4%9A%E6%9C%BA%E9%83%A8%E7%BD%B2.html</url>
    
    <content type="html"><![CDATA[<h2 id="一、主从模式"><a href="#一、主从模式" class="headerlink" title="一、主从模式"></a>一、主从模式</h2><p>为了避免机器挂掉或者出现故障就停止服务，或者是磁盘损坏丢失数据，Redis 提供了主从模式</p><p>一个主机负责读写，一个或多个从机负责读；主机挂掉之后，从机依然可以提供服务，可以由人工或者设置脚本，将其中一台从机设置为主机；</p><p>使用 slaveof&#x2F;replicaof 命令成为从机</p><p>主从之间要保证数据的一致性，主机的写操作要同步到从机</p><h3 id="1、第一次同步"><a href="#1、第一次同步" class="headerlink" title="1、第一次同步"></a>1、第一次同步</h3><p>当使用 slaveof &#x2F; replicaof 命令成为从机后，就要进行第一次同步，第一次同步分为三部分：</p><ul><li>建立链接，协商同步<ul><li>从机向主机发送 psync 命令，表示自己要进行数据同步；（有两个参数，runID 是每个 Redis 服务器在启动时产生的随机 id，此时从机并不知道主机的 runID，所以为 ？；  另一个参数为 offset，表示复制的进度，第一次为 -1）</li><li>主机收到后，向从机发送 fullresync 命令，表示是全量复制。（该命令也有两个参数，runID 和 offset，runID 为自己的 runID， offset 为主服务器目前的复制进度）</li><li>从机收到后保存主机的信息</li></ul></li><li>主机同步数据给从机<ul><li>主机发送完命令后，执行 bgsave 生成 RDB 文件，然后将 RDB 文件发送给从机</li><li>从机收到后，清空自己的数据，然后载入 RDB 文件</li><li>主机在执行 bgsave 命令、将 RDB 发送给从机 以及 从机载入 RDB 文件这段时间的写操作，并没有同步到从机；主机会将这段时间的写操作 写入到 repication buffer 缓冲区中</li></ul></li><li>主机发送新的写操作到从机<ul><li>当从机完成载入 RDB 操作后，发送命令给主机，告诉主机完成了</li><li>主机收到后，将 replication buffer 中的操作发送给从机，从机收到后执行，然后就完成了第一次同步的整个过程</li></ul></li></ul><h3 id="2、后续的同步"><a href="#2、后续的同步" class="headerlink" title="2、后续的同步"></a>2、后续的同步</h3><p> 主从之间会维持一个 TCP 连接，长连接；后续主机的写操作就同步这个连接传播给从机，从及执行命令完成同步</p><p> 这个过程被称为 基于长连接的命令传播；</p><h3 id="3、增量复制"><a href="#3、增量复制" class="headerlink" title="3、增量复制"></a>3、增量复制</h3><p>主从节点在第一次同步之后，就会通过 TCP 长连接进行命令传播；</p><p>但是，后续从节点可能出现掉线、重启等故障，此时主机的写操作就没有同步到从机；</p><p>等从机恢复后，主机的写操作如何同步到从机呢？    采用增量复制的方式</p><ul><li>连接恢复后，从机会发送 psync 命令给主机，offset 是从机目前的复制进度</li><li>主服务器收到命令后，然后发送 continue 命令告诉从机将以增量复制的方式同步数据</li><li>然后主机将从机断联这段时间的写操作发送给从机进行同步</li></ul><p>主服务器如何知道从什么位置进行增量数据同步呢？</p><p>主服务器有一个 repl_backlog_buffer，主服务器在进行写操作后，不仅通过命令传播将其发送给从机，还会写到这个缓冲区中；这个缓冲区是一个环形的缓冲区，大小默认为 1M，如果写满了就会不停的覆盖之前的数据；</p><p>主机通过从机发过来的 offset，与自己的 offset 进行对比，确定从机断联这段时间缺失的数据，然后去 repl_backlog_buffer 中找，如果找到了，则复制到 replication_buffer 中，然后传播给从机；</p><p>如果在 repl_backlog_buffer 中没有找到，则重新采用全量复制的方式</p><p>***** repl_backlog_buffer 一个主节点只会有一个，replication_buffer 是主节点为每一个从节点设置一个；</p><p>全量复制的开销很大，所以尽量保证 repl_backlog_buffer 中有缺失的操作，最简单的办法就是调整它的大小；一般调整的大小是：从机恢复所需时间的平均值 * 平均每秒产生的写命令的数据大小</p><p>更可靠的话可以调整为这个 2 倍</p><p><a href="https://xiaolincoding.com/redis/cluster/master_slave_replication.html#%E9%9D%A2%E8%AF%95%E9%A2%98">https://xiaolincoding.com/redis/cluster/master_slave_replication.html#%E9%9D%A2%E8%AF%95%E9%A2%98</a></p><h2 id="二、哨兵模式"><a href="#二、哨兵模式" class="headerlink" title="二、哨兵模式"></a>二、哨兵模式</h2><p>主从模式中，如果主服务器挂掉了，从服务器无法自动转为主服务器，要么就靠人工进行调换，要么就写一个脚本程序进行监控，这显然是不好的；</p><p>Redis 提供了哨兵模式来解决这一问题，Redis 哨兵可以监视主节点和从节点，如果主节点发生故障，哨兵可以选择合适的从节点转变为主节点，同时通知应用层以及其他从节点，主节点变了。</p><p>哨兵（sentinel）服务本质上还是 Redis 进程，执行特殊任务的 Redis 进程；</p><p>哨兵主要责任是：监控、选主、通知</p><h3 id="1、监控"><a href="#1、监控" class="headerlink" title="1、监控"></a>1、监控</h3><p>哨兵负责监控所有的主节点和从节点m</p><p>哨兵每隔一秒给所有的节点发送 PING 命令，如果节点在特定时间回应，则代表正常，不回应哨兵则将其标记为 <em>主观下线；</em></p><p>因为可能是由于网络拥塞等原因导致节点并没有响应，避免误判因此只是标记为主观下线； 所以，一般情况下，哨兵都是有多个组成哨兵集群（最少3台部署集群），通过多个哨兵进行监控，多个哨兵同时网络故障的可能性很小；</p><p>当某个哨兵发现节点无响应时，将其标记为主观下线，然后向其它哨兵发送命令，投票表示赞成还是反对，当有 quorum （配置项）个赞成时，将节点标记为客观下线；</p><p>如果是主节点，哨兵就要进行选主</p><h3 id="2、选主"><a href="#2、选主" class="headerlink" title="2、选主"></a>2、选主</h3><p>选主就是从所有从节点中选择合适的设置为新的主节点；  多个哨兵谁负责选主呢？？</p><p>此时就需要在所有哨兵中选举出一个 leader ，由他来负责选主</p><p>选举 leader 的过程：</p><ul><li>首先发现节点无响应，将其标记为客观节点的哨兵，作为候选者</li><li>候选者向其他哨兵发送命令，表明自己想成为 leader，让其他哨兵投票</li><li>其他哨兵投赞成或者反对票，每个哨兵只有一次投票机会，投完就不能投了；只有候选者可以把票投给自己，其他人都不可以</li><li>当赞成票超过一半，并且大于等于 quorum 参数时，候选者成功成为 leader</li></ul><p>这个也就是为什么集群最少是 3 个的原因：</p><p>当有两个哨兵同时发现节点客观下线，都会成为候选者，并且都投票给了自己，那么此时，两个候选者都成为不了 leader，无法进行主从切换</p><p>quorum 的大小一般为 哨兵节点个数 &#x2F; 2 + 1</p><p>哨兵节点个数一般为奇数</p><p>当leader 选举出来后，有它负责选主；</p><p>选主的过程：</p><ul><li>在从节点中选择一个作为新的主节点<ul><li>首先将网络不好的节点剔除</li><li>然后根据优先级选择优先级最高的</li><li>如果有多个优先级一样大的，在其中选择复制进度最大的（也就是offset 最接近主节点 offset 的从节点）</li><li>如果还有进度一样的，选择 id 最小的（每个 Redis 实例创建时都会有一个随机的 id）</li></ul></li><li>向选择好的从节点发送 slaveof no one 命令，将其设置为主节点</li><li>向其他所有的节点发送 slaveof 命令，将其他从节点的主节点变更</li><li>向客户端发送消息，说明主节点已经变化</li><li>持续监控旧的主节点，如果上线，将其设置为从节点</li></ul><h3 id="3、通知"><a href="#3、通知" class="headerlink" title="3、通知"></a>3、通知</h3><p>通知就是上述给从节点、客户端通知主节点变更</p><h2 id="三、集群模式（cluster）"><a href="#三、集群模式（cluster）" class="headerlink" title="三、集群模式（cluster）"></a>三、集群模式（cluster）</h2><p>单个 Redis 的读写能力已经很强了，tps 很高了，但是随着互联网的发展，一些场景比如双11，单机就很难支撑（集群主要是提升读写的能力，主从模式提升的只是读的能力）</p><p>所以就出现了集群模式</p><p>集群就是多个 Redis 节点，节点之间相互连接，但是存储不同的数据，通过哈希槽进行分片；</p><p>客户端会提前缓存哈希槽信息，在执行命令时，先使用 CRC16计算出16bits 的数据，然后对 16384 进行取余，确定到是哪个槽，确定是哪个节点负责的，然后直接请求；一般情况下，是没有问题的；</p><p>但是当集群新增或者删除节点，或者为了负载均衡重新分配哈希槽，这时客户端的缓存数据就没有用了，定位到的节点可能不准确，此时的节点会回应 MOVED，参数带上实际的节点ip 和端口，告知客户端这个槽不是自己的，是另一个人的；客户端收到后会进行重定向；</p><p>集群中总共有 16384 个槽，每个节点负责一部分；当操作的数据不在自己负责的槽上时，会重定向到负责的节点，然后获得数据；</p><p>每个节点会维护一个 clusterState 结构，里面有一个指针数组 slots[16384]，每一个数组元素的值是指向负责该槽的节点的指针；</p><blockquote><p>slot &#x3D; CRC16(key) % 16383</p></blockquote><p>集群模式的好处：客户端直接连接服务器，避免了各种 代理 Proxy 的性能损耗</p>]]></content>
    
    
    <categories>
      
      <category>Redis</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Redis-应用场景</title>
    <link href="/Redis/Redis-%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html"/>
    <url>/Redis/Redis-%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html</url>
    
    <content type="html"><![CDATA[<h2 id="一、缓存"><a href="#一、缓存" class="headerlink" title="一、缓存"></a>一、缓存</h2><h3 id="（一）缓存异常"><a href="#（一）缓存异常" class="headerlink" title="（一）缓存异常"></a>（一）缓存异常</h3><h4 id="1、缓存雪崩"><a href="#1、缓存雪崩" class="headerlink" title="1、缓存雪崩"></a>1、缓存雪崩</h4><h5 id="（1）什么是缓存雪崩："><a href="#（1）什么是缓存雪崩：" class="headerlink" title="（1）什么是缓存雪崩："></a>（1）什么是缓存雪崩：</h5><p>（大量的应用请求因为异常无法在 Redis 缓存中处理，从而直接打到数据库）</p><p>缓存雪崩是指，在同一时刻，许多 key 同时到期，导致大量的请求无法使用缓存而直接落在数据库上，最终造成数据库崩溃</p><h5 id="（2）怎么解决"><a href="#（2）怎么解决" class="headerlink" title="（2）怎么解决"></a>（2）怎么解决</h5><ul><li>均匀设置过期时间：可以在设置过期时间时采用随机数，防止大量 key 同时过期</li><li>重建缓存加互斥锁：线程在发现缓存中没有时，进行加锁，其他没有获取锁的线程阻塞或者返回空或错误，由成功获取锁的这一个线程去查询数据库，查到之后将数据添加到缓存。然后解锁； （针对不同的 key 加不同的锁）</li></ul><h4 id="2、缓存击穿"><a href="#2、缓存击穿" class="headerlink" title="2、缓存击穿"></a>2、缓存击穿</h4><p>缓存击穿是指：缓存中没有数据库中有的数据；    一般指某一热点数据过期，这一瞬间大量针对这一热点数据的请求无法使用缓存，落在数据库上，导致崩溃</p><p>解决方法：</p><ul><li>设置互斥锁：请求这一热点数据的线程在发现缓存中没有时，进行加锁，其他没有获取锁的线程阻塞或者返回空或错误，由成功获取锁的这一个线程去查询数据库，查到之后将数据添加到缓存。然后解锁；      这就避免了大量请求落在数据库上</li><li>热点数据支持续期：支持热点数据续期，当快要过期时，由后台线程更新数据过期时间</li></ul><h4 id="3、缓存穿透"><a href="#3、缓存穿透" class="headerlink" title="3、缓存穿透"></a>3、缓存穿透</h4><p>缓存穿透是指：大量请求针对的某一数据既不在缓存中也不在数据库中，请求数据库导致崩溃</p><p>（缓存穿透有可能是由于攻击者导致的，比如大量的请求 id 为 -1 的数据）</p><p>解决办法：</p><ul><li>设置默认值：当请求的数据既不在缓存也不在数据库中时，设置 key-value 为 key-null, 设定过期时间，不能太长（因为后续数据库可能添加了这个数据，但是由于缓存一直没过期，导致数据获取不到）</li></ul><blockquote><p>有缺点：如果攻击者每次都用不同的且都不存在的 key 来请求数据，那么这种措施毫无效果。并且，因为要回写特殊值，那么这些不存在的 key 都会有特殊值，浪费了 Redis 的内存。这可能会进一步引起另外一个问题，就是 Redis 在内存不足，执行淘汰的时候，把其他有用的数据淘汰掉。</p></blockquote><ul><li>布隆过滤器：使用布隆过滤器过滤大量请求，最终只有少部分落在数据库</li><li>增加校验：在接口层增加校验，比如对非法参数请求进行拦截、对攻击者ip进行拦截</li></ul><p>布隆过滤器：布隆过滤器底层是一个 64 位整型，根据 key 使用三个哈希函数生成对应的三个 hash 值，然后对 64 取余，获取三个索引，将对应索引位置更新为1；</p><p>后续请求该数据时，先进入布隆过滤器，如果根据请求的参数计算出的哈希值得到的索引位置上不都为 1， 则代表数据不存在，直接返回，不落在数据库上；如果都为1，则代表数据可能存在，接着去查数据库（布隆过滤器可以在查缓存之前查，也可以在查完缓存没有之后查，不同的方案罢了）</p><p>为什么可能存在呢？</p><p>因为数据量大的时候，发生哈希冲突的概率增大，有可能是其他数据使得那些位置为1，所以是有可能存在</p><p>布隆过滤器的优点是：占用空间小、速度快</p><p>缺点：还有一部分请求落在数据库上</p><h3 id="（二）缓存一致性问题"><a href="#（二）缓存一致性问题" class="headerlink" title="（二）缓存一致性问题"></a>（二）缓存一致性问题</h3><p>什么是缓存一致性问题？</p><p>缓存一致性问题是指，请求数据库数据时，缓存中如果不存在会添加到缓存中，后续的请求都会请求缓存；如果数据库中数据发生了改变，缓存如何和数据库保持一致</p><p>有三种思路：</p><ul><li>更新 MySQL，不管 Redis，仅仅使用过期时间兜底</li><li>更新 MySQL，更新 Redis</li><li>更新 MySQL，异步将更新同步到 Redis</li></ul><p>不能先操作 Redis 再操作数据库，因为 Redis 宕机后，数据可能就丢失了</p><h4 id="第一种：过期时间兜底"><a href="#第一种：过期时间兜底" class="headerlink" title="第一种：过期时间兜底"></a>第一种：过期时间兜底</h4><p>最简单的处理方法，缺点也很明显，设置时间太短则缓存频繁失效，太长更新不及时，达成一致性延迟高；</p><p>当然也有优点：Redis 的原生接口，实现简单； 管理成本低，不容易出问题</p><h4 id="第二种：先更新-MySQL，再更新-Redis"><a href="#第二种：先更新-MySQL，再更新-Redis" class="headerlink" title="第二种：先更新 MySQL，再更新 Redis"></a>第二种：先更新 MySQL，再更新 Redis</h4><p>更新 Redis 有两种：修改和删除</p><p>对于修改，容易造成时序性问题，所以不咋用；基本都用删除</p><p>删除也有问题，就是删除操作可能失败；此时就只剩过期时间，退化到了第一种</p><p>优点：相比第一种，达成一致性的延迟小；       实现成本小，只是增加了删除缓存的操作</p><p>缺点：删除操作可能失败，退化为第一种；       需要删除这一额外操作，消耗资源</p><h4 id="第三种：异步更新MySQL的修改到-Redis"><a href="#第三种：异步更新MySQL的修改到-Redis" class="headerlink" title="第三种：异步更新MySQL的修改到 Redis"></a>第三种：异步更新MySQL的修改到 Redis</h4><p>通过将搭建的消费服务设定为 MySQL 的 slave，订阅到 mysql 的 binlog，解析日志内容，再更新到 Redis；   适合数据不过期或者过期时间很长的场景，因为 解析 binlog 同步到 Redis 这个操作很重</p><p>优点：无时序性问题，可靠性强；        和业务逻辑解耦，不需要程序员关心具体操作</p><p>缺点：引入了消息队列这一比较重的组件，需要单独搭建消费服务，维护成本高；</p><p>​      如果压力过大，消费服务崩了，则很长一段时间 Redis 都是旧数据</p><h2 id="二、分布式锁"><a href="#二、分布式锁" class="headerlink" title="二、分布式锁"></a>二、分布式锁</h2><p>顾名思义，就是分布式场景下的锁，比如不同机器上的进程去竞争同一个资源，就需要加分布式锁</p><h3 id="1、分布式锁的特性"><a href="#1、分布式锁的特性" class="headerlink" title="1、分布式锁的特性"></a>1、分布式锁的特性</h3><ul><li>互斥性：锁是资源的使用权，因此要保证锁只能被特定数量的线程获得</li><li>安全性：线程获取锁之后如果发生了异常之类的情况不能解锁，需要有处理措施，否则资源会一直加锁，其他线程永远获取不到</li><li>对称性：解锁只能解自己加的锁，不能解掉别人的锁</li><li>可靠性：需要有一定的异常处理能力、容灾能力</li></ul><h3 id="2、如何保证互斥性"><a href="#2、如何保证互斥性" class="headerlink" title="2、如何保证互斥性"></a>2、如何保证互斥性</h3><p>使用 set 命令，加上 nx 参数，如果setnx 或者 set key value nx 返回了 1，说明之前没有人加锁，加锁成功，如果返回了0，说明已被加锁，加锁失败；</p><p>解锁时，delete 操作就行</p><h3 id="3、如何保证安全性"><a href="#3、如何保证安全性" class="headerlink" title="3、如何保证安全性"></a>3、如何保证安全性</h3><p>某线程加了锁，因为阻塞、异常甚至崩溃等原因不能返回解锁，导致锁一直无法释放，其他线程无法获得资源；</p><p>使用过期时间，锁到期就自动释放； 可以使用 expire 命令，但是由于 set 和 expire 不具有原子性，不能这样使用；</p><p>但是 Redis 有 ex 参数以及 px 参数， set k1 v1 nx ex 10 就是原子性的</p><h3 id="4、如何保证对称性"><a href="#4、如何保证对称性" class="headerlink" title="4、如何保证对称性"></a>4、如何保证对称性</h3><p>A线程加了锁，结果阻塞了，锁过期自动解锁了；此时B线程获得了锁，在处理业务； A从阻塞中恢复，并不知道锁已经被释放了，继续操作业务，操作完之后释放锁，结果释放的是 B 加的锁</p><blockquote><p>B此时没有锁了，执行完流程后释放锁操作，进行的是空操作</p></blockquote><p>针对这个问题，就要标明锁是谁的，设置 owner；很简单，在 set 的 value 中标注这是谁的，一般是将线程的 uuid 设置为 value；</p><p>释放锁时，先查一下这是不是自己的，如果是，再释放；</p><p>但是这还有一个问题！ 如果A线程释放锁时查到了这是自己的，还没有释放；此时锁过期了，B线程立马获取了锁，那么A释放的还是 B 的锁；</p><p>这个问题是由于：查锁和删除锁两个连起来不是原子化的；</p><p>Redis 引入 lua 脚本刚好解决这一问题，lua 脚本保证其中的操作是原子化的；</p><p>这下，分布式锁的特性前三个就满足了，互斥性、安全性、对称性</p><p>lua 脚本一定就能保证原子性吗？</p><p>lua 脚本本身并没有原子性，它是将多个操作放进一个流程中，相当于打包在一起；Redis 本身的核心处理逻辑是单线程的，所以执行一个流程时并不会被打断，因此才保证了这些操作的原子性；</p><p>lua 脚本执行时，如果发生了错误，那么，之前的所有操作还是生效的，不会回滚，后续的才不会执行</p><h3 id="5、如何保证可靠性"><a href="#5、如何保证可靠性" class="headerlink" title="5、如何保证可靠性"></a>5、如何保证可靠性</h3><p>保证可靠性，就是节点挂了、网络故障等等异常之后还能提供服务；</p><p>这种就采用两种方案，一种是 主从模式，另一种是 多机部署</p><h4 id="（1）主从模式"><a href="#（1）主从模式" class="headerlink" title="（1）主从模式"></a>（1）主从模式</h4><p>一个主 Redis 有多个从 Redis，当主 Redis 挂了之后，从 Redis 中选取一个变为主 Redis 继续提供服务；</p><p>那么，如何知道主 Redis 挂了，以及如何将从 Redis 变为 主Redis 呢？可以人为不停的去检查，发现挂掉之后，手动选择一个从Redis 转为 主Redis，并且通知上层应用；这样比较麻烦，可以采用脚本方式，自动去检测以及转换；其实，Redis 提供了成熟的解决方案，就是Redis 哨兵模式</p><p><em>哨兵模式</em></p><p>不需要人工参与，由哨兵节点自己决定主节点挂没挂，以及由哪个从节点转为主节点</p><p>哨兵模式一般都是多个哨兵节点；</p><p>但是主从模式有一个问题就是：当主节点A挂掉时，可能有一些数据还没有同步到从节点B；资源CCC的分布式锁信息恰好在这部分；主节点A挂掉后，从节点B接替为主节点B，此时，资源CCC的锁信息B并没有，其他线程此时申请锁，就申请到了；  这就产生了问题，导致两个线程同时持有了锁</p><p>更可靠的办法就是 <strong>多机部署</strong></p><h4 id="（2）多机部署"><a href="#（2）多机部署" class="headerlink" title="（2）多机部署"></a>（2）多机部署</h4><p>比如 Redis 的 RedLock ；定义是：有多个 Redis 主节点，这些主节点之间没有关系，完全相互独立；</p><p>操作：</p><ul><li>线程获取锁时，同时向 n 个主节点申请锁</li><li>一半以上的节点申请锁成功就算是申请到锁</li><li>如果没有一半以上的申请成功，则是申请失败，线程给所有节点发送解锁命令</li><li>申请成功后，由于网络请求需要时间，所以锁的实际剩余持有时间 &#x3D; 申请的时间 - 请求的时间</li><li>业务处理完毕后，线程给所有节点发送解锁命令</li></ul><p>优点：可靠性高，就算是有部分节点挂掉，也能继续提供服务</p><blockquote><p>每个主节点是相互独立的，普通主节点能实现的功能这些主节点也都有，比如哨兵模式等（比如说主节点 A，也可以有自己的从节点，有哨兵）</p></blockquote><h3 id="6、RedLock-一定可靠吗"><a href="#6、RedLock-一定可靠吗" class="headerlink" title="6、RedLock 一定可靠吗"></a>6、RedLock 一定可靠吗</h3><p>其实，也不一定可靠；</p><blockquote><p>由于分布式的三大困境，并没有完全可靠的分布式锁</p></blockquote><p>三大困境是 NPC，即 Network Delay（网络延迟）、Process Pause（进程暂停）、Clock Drift（时钟漂移）</p><p>RedLock 处理了 Network Delay 这一困境，其他的没有</p><h4 id="（1）Network-Delay"><a href="#（1）Network-Delay" class="headerlink" title="（1）Network Delay"></a>（1）Network Delay</h4><p>申请锁成功，节点回包给申请者，结果因为网络堵塞迟迟不能到申请者，等到了申请者，可能申请的锁已经过期了，那么此时就会出现问题，锁已经过期了申请者却不知道；</p><p>RedLock 已经解决了这个问题，在申请成功后，锁剩余的持有时间 &#x3D; 实际申请锁的时间 - 网络请求时间；网络请求时间是考虑在内的</p><h4 id="（2）Process-Pause"><a href="#（2）Process-Pause" class="headerlink" title="（2）Process Pause"></a>（2）Process Pause</h4><p>一个线程A申请到了锁，已经持有了，但是由于系统之类的问题（比如 JVM 的 GC），线程A暂停了；  此时锁过期了，另一个线程B申请到了锁；等线程A返回回来的时候，它并不知道自己的锁已经过期了； 那么就会出现多个线程持有同一把锁的情况</p><h4 id="（3）Clock-Drift"><a href="#（3）Clock-Drift" class="headerlink" title="（3）Clock Drift"></a>（3）Clock Drift</h4><p>时钟偏移是指时钟突然变化（细节不管）</p><p>假设多机部署有5个主节点，线程A向三个节点申请锁成功了，此时A就成功获取到了锁；</p><p>之后，三台中的一台发生了时钟漂移，导致锁立马过期了；B线程又恰好向包含时钟漂移的这个节点的三个节点申请成功了，那么，此时就会出现两个线程同时持有锁的情况；</p><h3 id="7、总结"><a href="#7、总结" class="headerlink" title="7、总结"></a>7、总结</h3><p>分布式锁没有完全可靠的，要根据实际应用场景选择合适的，一般情况都用的是 主从模式，RedLock 很少用；</p><h2 id="三、事务"><a href="#三、事务" class="headerlink" title="三、事务"></a>三、事务</h2><p>什么是事务？ 多个操作被看作一个整体，一起执行；事务一般具有原子性</p><h3 id="1、Multi-事务"><a href="#1、Multi-事务" class="headerlink" title="1、Multi 事务"></a>1、Multi 事务</h3><p>Redis 原生有 Multi 命令，用于开启事务；</p><p>整个事务的执行是由几个命令构成：Watch、Multi、Exec、Discard</p><ul><li>Multi：用于开启事务，开启后，所有的命令都会加入到事务队列中</li><li>Exec：执行事务</li><li>Discard：放弃事务，执行后事务取消，已经加到事务队列中的命令就无效了</li><li>Watch：用于监视事务中操作的 key；一般的操作：在 Multi 开启事务之前执行 Watch，监视某几个 key，Multi 开启事务后，操作这几个 key ，如果在事务执行之前，有其他客户端修改了监视的 key，则事务执行不成功；</li></ul><p>multi：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>:<span class="hljs-number">6379</span>&gt; multi<br>OK<br><span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>:<span class="hljs-number">6379</span>&gt; set a <span class="hljs-number">1</span><br>QUEUED<br><span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>:<span class="hljs-number">6379</span>&gt; set b <span class="hljs-number">2</span><br>QUEUED<br><span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>:<span class="hljs-number">6379</span>&gt; exec<br><span class="hljs-number">1</span>) OK<br><span class="hljs-number">2</span>) OK<br><span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>:<span class="hljs-number">6379</span>&gt; keys *<br><span class="hljs-number">1</span>) <span class="hljs-string">&quot;b&quot;</span><br><span class="hljs-number">2</span>) <span class="hljs-string">&quot;a&quot;</span><br><span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>:<span class="hljs-number">6379</span>&gt;<br></code></pre></td></tr></table></figure><p>watch：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs Java">终端<span class="hljs-number">1</span>：<br><br><span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>:<span class="hljs-number">6379</span>&gt; watch a<br>OK<br><span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>:<span class="hljs-number">6379</span>&gt; multi<br>OK<br><span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>:<span class="hljs-number">6379</span>&gt; set a a<br>QUEUED<br><span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>:<span class="hljs-number">6379</span>&gt; set b b<br><br>终端<span class="hljs-number">2</span>：<br><br><span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>:<span class="hljs-number">6379</span>&gt; set a <span class="hljs-number">1</span><br>OK<br><br>终端<span class="hljs-number">1</span>：<br><br><span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>:<span class="hljs-number">6379</span>&gt; exec<br>(nil)<br></code></pre></td></tr></table></figure><p>当 watch 监视的 key 被修改时，事务回滚，操作无效</p><p>Multi 并不具备原子性，他只是将命令添加在一起，一块执行，依赖的还是 Redis 核心逻辑单线程执行，Multi 操作不会被打断；看起来就是原子操作</p><p>Multi 事务不使用 watch 时不支持回滚，事务中有命令执行失败时，其他命令还是会执行成功；</p><p>注意：执行失败是指执行的时候出错，而不是输入命令编译就出错等情况，编译出错等情况下，整个事务执行失败</p><p>Multi事务的缺点：</p><ol><li>事务开启后，每个命令都是一次调用，消耗资源</li><li>事务开启后，防止事务中的 key 被修改，还需要 watch 命令，操作繁琐</li><li>事务中的命令执行出错时，其他命令能正常执行，令人疑惑</li></ol><h3 id="2、Lua-事务"><a href="#2、Lua-事务" class="headerlink" title="2、Lua 事务"></a>2、Lua 事务</h3><p>Lua 是使用标准 C 语言写的轻量的脚本语言，目的是嵌入到应用程序中，为应用程序提供灵活的扩展和定制功能；       Lua 脚本实际上是将许多命令添加到一个流程中，相当于打包；</p><p>Lua 的执行命令为 eval</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>:<span class="hljs-number">6379</span>&gt; eval <span class="hljs-string">&quot;return &#123;redis.call(&#x27;set&#x27;, &#x27;a&#x27;, &#x27;ww&#x27;), redis.call(&#x27;set&#x27;, &#x27;b&#x27;, &#x27;ss&#x27;)&#125;&quot;</span> <span class="hljs-number">0</span><br><span class="hljs-number">1</span>) OK<br><span class="hljs-number">2</span>) OK<br><span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>:<span class="hljs-number">6379</span>&gt; get a<br><span class="hljs-string">&quot;ww&quot;</span><br><span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>:<span class="hljs-number">6379</span>&gt; get b<br><span class="hljs-string">&quot;ss&quot;</span><br></code></pre></td></tr></table></figure><blockquote><p>如果执行过程中发生错误，之前的仍然是执行成功，之后的停止执行</p></blockquote><p>很明显，Lua 的使用很方便，不需要那么多命令配合</p><p>Lua 在 Redis 中常用的场景就是 分布式锁 、秒杀</p><h2 id="四、消息队列"><a href="#四、消息队列" class="headerlink" title="四、消息队列"></a>四、消息队列</h2><p>消息队列就是传递消息的队列，先入先出，一般用于 异步流程、消息分发、流量削峰等；</p><p>Redis 中可以用作队列的：</p><h3 id="1、List"><a href="#1、List" class="headerlink" title="1、List"></a>1、List</h3><p>虽然 List 是双端操作，不过在用作消息队列时，可以设定只能左进右出或者右进左出；</p><p>Lpush 放进消息，Rpop 取出消息；但是这样的话消费者不知道什么时候有消息，得一直询问；所以有了 BRPOP 、BLPOP 阻塞取出，命令格式为 BRPOP key seconds；  seconds 为限定时间，如果这么长时间没有消息，就返回； 这个阻塞命令只能接收一条消息，接收到就返回；</p><p>List 的缺点：不支持 ACK（消息取出后就出队列了，如果消费失败，消息放不回去）； 不支持多消费者消费</p><h3 id="2、Pub-Sub-生产订阅模式"><a href="#2、Pub-Sub-生产订阅模式" class="headerlink" title="2、Pub&#x2F;Sub 生产订阅模式"></a>2、Pub&#x2F;Sub 生产订阅模式</h3><p>Redis 支持发布订阅模式</p><p>当订阅者订阅了某个频道时，有消息它就会感知到；支持多消费者消费，每个消息每个消费者都能消费一次</p><blockquote><p>需要消费者先订阅，不然订阅之前生产的消息生产失败</p></blockquote><p>缺点：没有 ACK，消费失败后消息也放不回；        没有持久化，系统宕机消息就丢失了</p><h3 id="3、Stream"><a href="#3、Stream" class="headerlink" title="3、Stream"></a>3、Stream</h3><p>Stream 可以作为轻量级消息队列，是 Redis 中最完备的消息队列</p><p>优点：支持 ACK，支持消费组， 支持持久化</p><p>缺点：跟真正的消息队列相比可靠性还有很大差距； 等等</p><h3 id="4、总结"><a href="#4、总结" class="headerlink" title="4、总结"></a>4、总结</h3><p>List：不需要 ACK、不需要消费组 的场景可用</p><p>Pub&#x2F;Sub 生产订阅模式：不需要 ACK、不需要持久化、不需要消费组 的场景可用（相比 List 的优点在于 支持多消费者，默认是阻塞获取消息，有了消息后消费者是知道的）</p><p>Stream：需要 ACK、需要消费组、需要持久化 的场景可以用</p><h2 id="五、秒杀"><a href="#五、秒杀" class="headerlink" title="五、秒杀"></a>五、秒杀</h2><p>秒杀需要考虑几个问题：高并发、超卖、少卖       后续补充……..</p>]]></content>
    
    
    <categories>
      
      <category>Redis</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Redis-持久化</title>
    <link href="/Redis/Redis-%E6%8C%81%E4%B9%85%E5%8C%96.html"/>
    <url>/Redis/Redis-%E6%8C%81%E4%B9%85%E5%8C%96.html</url>
    
    <content type="html"><![CDATA[<h2 id="一、持久化介绍"><a href="#一、持久化介绍" class="headerlink" title="一、持久化介绍"></a>一、持久化介绍</h2><h3 id="1、什么是持久化"><a href="#1、什么是持久化" class="headerlink" title="1、什么是持久化"></a>1、什么是持久化</h3><p>Redis 是内存 K-V 数据库，数据是在内存中的，如果系统宕机或者关机，数据就丢失了；为了使开机后数据还在，就需要将数据保存到可永久保存的存储介质中，这就是持久化</p><h3 id="2、持久化方式"><a href="#2、持久化方式" class="headerlink" title="2、持久化方式"></a>2、持久化方式</h3><p>Redis 有两种持久化方式，一种是 RDB（Redis DataBase），一种是AOF（Append Only File）；Redis 默认开启的是 RDB，而AOF 需要手动开启；</p><ul><li>RDB 是全量的二进制格式数据快照，记录某个时刻的全部数据，后续通过加载 RDB 文件恢复数据；</li><li>AOF中记录的是修改数据的命令，并且是以追加方式进行的，本质就是记录操作日志；后续通过加载 AOF 文件重放命令来恢复数据</li></ul><p>因此，RDB 的持久化文件 .rdb 是人不可读的，而 AOF 的持久化文件是人可读的</p><p>RDB和AOF的区别：</p><ul><li>恢复速度方面：RDB 是数据快照，可以直接恢复；AOF 是执行日志，需要重放操作进行恢复；因此 RDB 要快很多</li><li>体积方面：RDB 存放的是二进制紧凑型的数据；AOF 存放的是每条修改指令；相同数据量下，RDB 文件所占用空间更小</li><li>数据完整性：AOF 是记录每一条修改命令，RDB 每隔一段时间记录一次，AOF 恢复数据通常会更完整</li></ul><h3 id="3、选用什么？"><a href="#3、选用什么？" class="headerlink" title="3、选用什么？"></a>3、选用什么？</h3><p>对于用于缓存并且不是海量访问的情况，可以不使用缓存</p><p>RDB 默认开启，AOF 选择性开启；</p><p>因为 RDB 是全量快照，所以需要隔一段时间进行，不然消耗CPU资源太多；而 AOF 是增量型的，每次操作都会记录，并且根据设置选择刷盘的频率时间；</p><p>所以，对于丢失数据不可忍的场景，应该使用 AOF；其他场景可以使用 RDB</p><p>AOF 不建议单独开启，如果要开启 AOF，建议和 RDB 一同开启；一同开启后，恢复时，只会加载 AOF 文件，如果存在则进行恢复。如果不存在，不会使用 RDB 文件，而是创建一个空库；</p><p>这样的原因是：</p><p>如果用户开启了 AOF，说明对数据丢失的容忍性很小，对数据的完整度要求很高；</p><p>RDB 全量快照可能在几分钟前，那么就会丢失掉最近几分钟的数据，系统默认这样是不行的；</p><p>但是，RDB 文件还是在的，如果数据确定丢失了找不回来，那么可以通过 RDB 恢复，代价是丢失几分钟的数据</p><p>为什么 RDB 是几分钟做一次持久化？</p><p>RDB 因为保存的是全量的二进制数据快照，尽管可以通过主进程 fork 一个子进程在后台进行 RDB 操作，但是如果一分钟做一次，消耗的资源还是会比较多；有可能上一次 RDB 还没做完，下一秒又 fork 一个子进程做；主进程 fork 子线程也会消耗资源，造成阻塞；</p><h2 id="二、RDB-详解"><a href="#二、RDB-详解" class="headerlink" title="二、RDB 详解"></a>二、RDB 详解</h2><h3 id="1、怎样开启-RDB-持久化"><a href="#1、怎样开启-RDB-持久化" class="headerlink" title="1、怎样开启 RDB 持久化"></a>1、怎样开启 RDB 持久化</h3><p>Redis 是默认开启 RDB 的</p><p>配置文件中可以设置 RDB 的阈值，比如说几分钟内有几条写操作就触发 RDB 持久化</p><p>Redis 的默认设置是：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs Java">save <span class="hljs-number">900</span> <span class="hljs-number">1</span><br>save <span class="hljs-number">300</span> <span class="hljs-number">10</span><br>save <span class="hljs-number">60</span> <span class="hljs-number">10000</span><br></code></pre></td></tr></table></figure><p>意思就是如果900s内有1次写操作，就触发，这三条是或的关系</p><h3 id="2、RDB-文件存放在哪"><a href="#2、RDB-文件存放在哪" class="headerlink" title="2、RDB 文件存放在哪"></a>2、RDB 文件存放在哪</h3><p>Redis 配置文件中有指定</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs Java">#指定 rdb 文件名称<br>dbfilename dump.rdb<br><br>#指定存放位置<br>dir ******<br></code></pre></td></tr></table></figure><p>最终生成的RDB文件是一堆乱码，因为是二进制格式；但是最开头会有 REDIS 这个字符串标识</p><h3 id="3、什么时候持久化"><a href="#3、什么时候持久化" class="headerlink" title="3、什么时候持久化"></a>3、什么时候持久化</h3><ul><li>当超过了配置文件设定的阈值时，bgsave，非阻塞式持久化    （周期函数会定期检查是否到达了阈值，默认是 100ms 检查一次）</li><li>当主动执行 save、bgsave 命令时；save 是阻塞式持久化；bgsave 是非阻塞式</li><li>当关闭redis 时，会进行阻塞式持久化</li></ul><h3 id="4、RDB-如何进行持久化"><a href="#4、RDB-如何进行持久化" class="headerlink" title="4、RDB 如何进行持久化"></a>4、RDB 如何进行持久化</h3><ul><li>主进程 fork 出一个子进程，进行非阻塞式持久化</li><li>子进程创建一个临时 rdb 文件，保存全量的二进制数据快照</li><li>使用临时 rdb 文件替换掉旧的 rdb 文件</li></ul><p>fork 命令创建子进程时，会将父进程的页表复制给子进程，也就是新建PCB 之后，将父进程的 PCB中的信息复制给子进程的PCB；</p><p>父进程子进程页表一样，共享同一片内存空间</p><p>这里还有个点，如果子进程在持久化过程中，父进程发生了写操作，那么就会引起写时复制；</p><p>写时复制（Copy-On-Write，简称COW ）：</p><p>父进程在创建子进程时，为了提高创建速度以及节省不必要的内存开销，不会给子进程分配物理空间，而是将父进程的页表复制给子进程，父子进程使用同一块物理空间；此时的内核会将父进程的所有内存页设置为 read-only，如果后续父子进程有了写操作，就会触发页异常中断；内核此时就会将触发异常的页复制一份，于是父子进程各自持有独立的一份；</p><p><a href="https://blog.csdn.net/qq_32131499/article/details/94561780">https://blog.csdn.net/qq_32131499/article/details/94561780</a></p><p>Redis 中，此时子进程指向的还是旧的物理空间，所以此时的写操作的数据并不会保存在本次 RDB持久化中；</p><h2 id="三、AOF-详解"><a href="#三、AOF-详解" class="headerlink" title="三、AOF 详解"></a>三、AOF 详解</h2><h3 id="1、怎样开启-AOF"><a href="#1、怎样开启-AOF" class="headerlink" title="1、怎样开启 AOF"></a>1、怎样开启 AOF</h3><p>配置文件中 </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs Java">appendonly no<br>appendfilename <span class="hljs-string">&quot;appendonly.aof&quot;</span><br></code></pre></td></tr></table></figure><p>设置 appendonly 为 yes 就开启了 AOF，可以看出，Redis 是默认关闭 AOF 的；</p><p>开了 AOF 后，每条修改数据的命令都会记录下来；恢复时，通过重放命令进行恢复，这个操作耗时一些；</p><p>Redis 设置key 过期的指令执行时，过期时间会转化为过期时的时间戳，因此，对于这类命令重放时，已经过期的就不存储，还没过期的就存储过期时的时间戳</p><h3 id="2、AOF-写入流程"><a href="#2、AOF-写入流程" class="headerlink" title="2、AOF 写入流程"></a>2、AOF 写入流程</h3><p>AOF 的写入流程为：</p><ol><li>当执行一条修改命令时，执行成功后将其写入到 AOF 缓冲区</li><li>根据指定的刷盘策略，将缓冲区数据刷入到磁盘</li></ol><p>这里，刷盘策略有三种：</p><ol><li>Appendfsync always: 每执行一次命令，立马刷盘</li><li>Appendfsync everysec: 每秒刷一次盘</li><li>Appendfsync no：不主动刷盘，让操作系统刷，Linux 一般是 30 s</li></ol><p>Redis 推荐的刷盘策略是 everysec，每1s刷一次盘，性能也不会影响太多，丢失最多1s 的数据；</p><p>如果非常追求性能，并且可以容忍丢失很长时间的数据，那么也可以选择 no</p><p>Always 一般不会用，Redis 的定位也不是完全可靠</p><p>Always 策略是同步刷盘，会阻塞主线程</p><p>Everysec 是后台线程异步刷盘</p><h3 id="3、AOF-写入细节"><a href="#3、AOF-写入细节" class="headerlink" title="3、AOF 写入细节"></a>3、AOF 写入细节</h3><p>写入其实分了好几步：</p><p>（1）写入 AOF 缓冲区</p><p>这个缓冲区其实是一个 sds，名字叫 aof_buf</p><p>（2）从 AOF 缓冲区刷入到到磁盘缓存，也就是 pagecache（操作系统缓冲区）</p><p>会有四个时机做这个，先不了解</p><p>（3）从磁盘缓存刷入到磁盘中</p><p>这一步就跟设置的刷盘策略紧密相关；调用系统的 flush 函数</p><h3 id="4、AOF重写"><a href="#4、AOF重写" class="headerlink" title="4、AOF重写"></a>4、AOF重写</h3><p>AOF文件是不断写入的，这就导致一个问题：AOF 文件会不断膨胀；</p><p>针对这个问题，Redis 采用了重写的办法：</p><p>具体来说，就是当 AOF 文件大于 64M ，并且相比于上次已经增长了 100%时，自动 fork 一个子进程，进行 AOF 重写；子进程根据Redis中所有的数据，生成相应的命令，（比如说看到了 a 1，就会生成 set a 1），然后放入临时 AOF 文件中；</p><p>同时，如果此时主进程还执行了写操作，则会将命令写入到 AOF缓冲区 和 AOF 重写缓冲区；等子进程重写完毕后，就将 AOF 重写缓冲区中的数据追加到新的AOF文件中，然后用新的 AOF 文件替换掉旧的。</p><blockquote><p>重写的原理，比如执行了 set a 1，然后后来又执行了 set a 2，那么前一条已经没有意义了</p></blockquote><p>1、为什么不直接复用原来的 AOF 文件？</p><p>因为如果重写操作失败，原来的AOF文件重写了一半就用不了了</p><p>2、为什么写操作后要分别写入 AOF 缓冲区 和 AOF 重写缓冲区呢？</p><p>如果没有 AOF 重写缓冲区，那么当重写过程中主进程执行了写操作修改了数据，而此时子进程是不知道的，最后生成的新的AOF文件就与内存数据不一致</p><h2 id="四、AOF优化-混合持久化"><a href="#四、AOF优化-混合持久化" class="headerlink" title="四、AOF优化-混合持久化"></a>四、AOF优化-混合持久化</h2><h3 id="1、什么是混合持久化"><a href="#1、什么是混合持久化" class="headerlink" title="1、什么是混合持久化"></a>1、什么是混合持久化</h3><p>混合持久化是指，在 AOF 重写时，将当前数据库状态通过 rdb 二进制快照保存下来，然后将重写期间的写操作命令以 AOF 文件的格式追加到 rdb 二进制后面</p><h3 id="2、为什么要混合持久化"><a href="#2、为什么要混合持久化" class="headerlink" title="2、为什么要混合持久化"></a>2、为什么要混合持久化</h3><p>混合持久化是结合了 RDB 和 AOF 的优点；混合持久化之后，前半段是 RDB 二进制文件，恢复数据的速度很快，后半部分是持久化期间的操作命令，使得数据更少的丢失。</p><p>混合持久化大大降低了 AOF 重写期间的性能消耗，以及减少了 AOF 文件的空间占用（因为RDB文件是紧凑型的二进制数据文件）；但是代价是丧失了人的可读性</p><p>开启混合持久化需要在配置文件中开启 aof-use-rdb-preamble；  目前使用的版本是默认开启的，也就说，只要你开启了 AOF，就默认开启了混合持久化</p><h3 id="3、混合持久化文件恢复"><a href="#3、混合持久化文件恢复" class="headerlink" title="3、混合持久化文件恢复"></a>3、混合持久化文件恢复</h3><p>混合持久化文件还是 AOF 文件，只不过前半部分是 二进制数据，是乱码；</p><p>最开始会有 REDIS 几个字符，就标志着这是个混合持久化的AOF文件；</p><h2 id="五、AOF优化-MP方案"><a href="#五、AOF优化-MP方案" class="headerlink" title="五、AOF优化-MP方案"></a>五、AOF优化-MP方案</h2><p>MP：Multi Part AOF</p><h3 id="1、AOF重写的缺陷"><a href="#1、AOF重写的缺陷" class="headerlink" title="1、AOF重写的缺陷"></a>1、AOF重写的缺陷</h3><ul><li>占用主进程CPU时间：AOF重写时，如果有写操作，需要主进程分别向 AOF 缓冲区和 AOF 重写缓冲区写入新的写操作命令；以及子进程重写结束后，将 AOF 重写缓冲区的内容写入到新的 AOF 文件</li><li>占用额外内存：这两份数据是一样的，造成了内存的额外占用（AOF 重写缓冲区）；</li><li>额外磁盘开销：重写完成后，主进程不仅需要将 AOF 缓冲区的内容写到旧的 AOF 文件中，还需要将 AOF 重写缓冲区的内容写到新的 AOF 文件中；多了一次磁盘消耗，而这两份数据是一样的；</li></ul><h3 id="2、改进"><a href="#2、改进" class="headerlink" title="2、改进"></a>2、改进</h3><p>针对这些问题，Redis 7.0提出了改进，采用了 MP方案，Multi Part AOF，也就是使用两个 AOF 文件；</p><p>具体描述：</p><p>采用两个 AOF 文件，base aof 和 incr aof；这两个文件组合起来，就是完整的操作</p><p>base aof 用于重写时，将数据库的数据转化为操作记录下来；incr aof 用于将重写过程中的写操作指令记录下来，即将AOF缓冲区中的内存写入进去；当重写完成后，更新 .manifeat 文件，记录新的这两个 base aof 和 incr aof 文件；将旧的base aof 和 incr aof 记录为 history；  后续通过后台线程异步进行删除</p><p>这样改造的话，就不需要再有一个 AOF 重写缓冲区；也不需要主进程再多次将 AOF 重写缓冲区内容写入新的 AOF 文件；</p>]]></content>
    
    
    <categories>
      
      <category>Redis</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Redis-如何运作</title>
    <link href="/Redis/Redis-%E5%A6%82%E4%BD%95%E8%BF%90%E4%BD%9C.html"/>
    <url>/Redis/Redis-%E5%A6%82%E4%BD%95%E8%BF%90%E4%BD%9C.html</url>
    
    <content type="html"><![CDATA[<h2 id="一、Redis在内存中怎样存储"><a href="#一、Redis在内存中怎样存储" class="headerlink" title="一、Redis在内存中怎样存储"></a>一、Redis在内存中怎样存储</h2><h3 id="存储数据"><a href="#存储数据" class="headerlink" title="存储数据"></a>存储数据</h3><p>RedisDB 代表 Redis 的数据库结构，如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs Java">typedef struct redisDb &#123;<br>    dict *dict;<br>    <span class="hljs-comment">/* The keyspace for this DB */</span><br>    dict *expires;<br>    <span class="hljs-comment">/*Timeout of keys with a timeout set */</span><br>    dict *blocking_keys;<br>    <span class="hljs-comment">/* Keys with clients waiting for data (BLPOP)*/</span><br>    dict *ready_keys;<br>    <span class="hljs-comment">/* BLocked keys that received a PUSH */</span><br>    dict *watched_keys;<br>    <span class="hljs-comment">/*WATCHED keys for MULTI/EXEC CAS*/</span><br>    <span class="hljs-type">int</span> id;<br>    <span class="hljs-comment">/* Database ID */</span><br>    <span class="hljs-type">long</span> <span class="hljs-type">long</span> avg_ttl;<br>    <span class="hljs-comment">/* Average TTL, just for stats */</span><br>    list *defrag_later;<br>    <span class="hljs-comment">/* List of key names to attempt to defrag one by one, gradually */</span><br>&#125;redisDb;<br></code></pre></td></tr></table></figure><p>dict：字典，存储实际的数据；跟 hashtable 渐进式扩容中的字典是一样的</p><p>expires：过期字典，存放设定了过期时间的 key 以及过期时的时间戳</p><p>dict 的结构：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs Java">typedef struct dict &#123;<br>    dictType *type;<br>    <span class="hljs-keyword">void</span> *privdata;<br>    dictht ht[<span class="hljs-number">2</span>];<br>    <span class="hljs-type">long</span> rehashidx;<span class="hljs-comment">/*rehashing not in progress if rehashidx==-1*/</span><br>    unsigned <span class="hljs-type">long</span> iterators;<span class="hljs-comment">/* number of iterators currently running */</span><br>&#125; dict;<br></code></pre></td></tr></table></figure><h3 id="过期键"><a href="#过期键" class="headerlink" title="过期键"></a>过期键</h3><p>过期键实际是存储在 expires 字典上</p><p>value 为key过期时间的时间戳</p><p>注意，不管是 dict 还是 expires 字典，存储的 key 都不是真正的 key 字符串，而是指向key字符串的指针；  也就是说，在内存中有一块区域存储 key 字符串，dict 的 key 和 expires 的key 都指向它 </p><h2 id="二、Redis-是单线程还是多线程"><a href="#二、Redis-是单线程还是多线程" class="headerlink" title="二、Redis 是单线程还是多线程"></a>二、Redis 是单线程还是多线程</h2><p><strong>Redis 的核心处理逻辑是单线程</strong>；辅助模块会有多线程、多进程等，比如复制模块用的多线程、UNLINK 等非阻塞的删除使用的多线程、网络 I&#x2F;O 解包从 6.0 开始是多线程；</p><p>注意，Redis 单线程指的是 接收到请求 -&gt; 解析请求 -&gt; 具体操作 -&gt; 响应回包  这一串是单线程，无法被打断；比如说 set k1 v1 ，这个操作就是原子性的，不能被打断，只能单线程执行；</p><p>但是 set k1 v1;   expire k1 10 这两条合在一块就不是原子性了</p><h3 id="1、为什么选择单线程"><a href="#1、为什么选择单线程" class="headerlink" title="1、为什么选择单线程"></a>1、为什么选择单线程</h3><p>Redis 的定位是内存 K-V 存储，一般用来存储短平快的热点数据，本身执行就很快，不应该成为瓶颈；瓶颈应该在网络 I&#x2F;O 上；使用多线程并不会带来太大的收益</p><p>而且 Redis 的设计初衷就是简单、可维护，如果使用多线程，则增加了极大的复杂性</p><h4 id="（1）多线程引入极大的复杂性"><a href="#（1）多线程引入极大的复杂性" class="headerlink" title="（1）多线程引入极大的复杂性"></a>（1）多线程引入极大的复杂性</h4><ul><li>首先，如果引入多线程，Redis 的单线程执行的原子性、隔离性就不复存在了；需要为了执行流程的确而增加大量额外的工作，比如加锁、解锁等等</li><li>而且，Redis 的底层存储结构设计的非常好，做了极大的优化；如果使用多线程，由于线程不安全，这些数据结构就需要重新设计改造</li><li>再者，多线程使得编程、操作等变得复杂，调试也难度更高，更容易出错</li></ul><h4 id="（2）多线程带来较大的开销"><a href="#（2）多线程带来较大的开销" class="headerlink" title="（2）多线程带来较大的开销"></a>（2）多线程带来较大的开销</h4><ul><li>多线程下，线程的上下文切换消耗资源</li><li>为了同步，需要加锁、解锁等操作，也有较大开销</li><li>线程本身就需要占用空间，Redis 由于在内存中，对空间的消耗非常敏感</li></ul><h2 id="三、Redis-单线程为什么这么快"><a href="#三、Redis-单线程为什么这么快" class="headerlink" title="三、Redis 单线程为什么这么快"></a>三、Redis 单线程为什么这么快</h2><ul><li>Redis 的数据存储结构设计的很好，并且每种数据类型都有多种编码方式供不同场景使用</li><li>Redis 在内存中，内存中的操作本身就很快</li><li>Redis 使用了 I&#x2F;O 多路复用机制，使其能在网络 I&#x2F;O 请求中，并发的处理请求</li></ul><h3 id="1、I-O-多路复用机制："><a href="#1、I-O-多路复用机制：" class="headerlink" title="1、I&#x2F;O 多路复用机制："></a>1、I&#x2F;O 多路复用机制：</h3><p>Redis 在启动时，已经绑定了端口，监听连接；Redis 的整个处理流程是：</p><ul><li>客户端请求到来，调用 accept 建立连接</li><li>调用 recv 从套接字中获取客户端发来的请求 </li><li>解析请求，获取请求参数</li><li>执行核心处理逻辑获取请求结果</li><li>调用 send 发送结果</li></ul><p>默认情况下，套接字是阻塞模式的，阻塞发生在两个地方，accept 和 recv；</p><p>比如说 accept 建立连接时间过长，会导致 accept 阻塞；或者客户端迟迟不发请求，导致 recv 操作发生阻塞；而一旦发生阻塞，Redis 就被迫停止其他服务了；</p><p>针对这个问题，Redis 将 accpet 和 recv 操作设置为非阻塞，也就说，如果这两个操作没有响应，就去执行其他任务； 那么，此时就需要一种方式，来监控 accept、recv 这些操作后来是否就绪；</p><p>常见的方式就是轮询，显然十分低效；好消息是，操作系统实现了 I&#x2F;O 多路复用机制；简单来说，就是如果 I&#x2F;O 操作触发，就会产生通知，收到通知，再去处理通知对应的具体事件</p><p>Redis 对 I&#x2F;O 多路复用做了一层封装，称为 Reactor 模型；本质就是监听各种事件（事件是由epoll产生的），当事件发生时，将事件分发给不同的处理器</p><p>这样就不会阻塞在某一个操作上，I&#x2F;O 多路复用让 Redis 单线程下也有了较大的并发度</p><h2 id="四、多线程是怎么回事"><a href="#四、多线程是怎么回事" class="headerlink" title="四、多线程是怎么回事"></a>四、多线程是怎么回事</h2><p>注意的点：多线程体现在读命令和数据、进行解析、以及回包，也就是将缓冲区的结果通过 socket 发送给客户端； 也就是说，数据准备好了之后，内核通知应用程序，主线程才转去处理，将这些连接分发给 I&#x2F;O 多线程</p><p>I&#x2F;O 线程要么全在读，要么全在写；因为主线程在分发等待读任务时，是阻塞的，直到所有的 I&#x2F;O 线程处理完读；   写任务也是一样；     **** 主线程在分发任务时，也会给自己分发一份，然后阻塞等待所有的任务都被完成；</p><blockquote><p>Redis 初始化时，会根据配置文件设定的参数创建I&#x2F;O 线程，创建成功后就进行了循环，一直执行，直到Redis 进程关闭；</p></blockquote><h2 id="五、内存满了怎么办"><a href="#五、内存满了怎么办" class="headerlink" title="五、内存满了怎么办"></a>五、内存满了怎么办</h2><p>在 32 位机器上，总内存只有 4G，系统本身就需要一些资源，所以 Redis 的最大内存是 3G；</p><p>而在 64 位机器上，不限制内存的使用；但是也可以通过 maxmemory 来配置</p><p>如果 Redis 的内存占用达到了上限，那么就有这么8种处理策略</p><ol><li>noeviction（默认）：满了之后不做处理，添加新数据失败</li><li>针对设置了过期时间的键：</li></ol><p>LRU：（Least Rencently Used）最近最少使用的进行淘汰，腾出空间给新数据用</p><p>LFU：（Least Frequently Used）最近最不频繁使用的进行淘汰</p><p>Random：随机淘汰</p><p>TTL：离过期时间最近的进行淘汰</p><ol><li>针对所有的键：</li></ol><p>LRU：（Least Rencently Used）最近最少使用的进行淘汰，腾出空间给新数据用</p><p>LFU：（Least Frequently Used）最近最不频繁使用的进行淘汰</p><p>Random：随机淘汰</p><h3 id="1、淘汰策略选择"><a href="#1、淘汰策略选择" class="headerlink" title="1、淘汰策略选择"></a>1、淘汰策略选择</h3><p>针对不同的场景选用不同的淘汰策略：</p><p>比如数据都很重要的场景，就需要 noeviction 策略； 比如使用缓存的场景，就会使用 LRU&#x2F; LFU</p><h3 id="2、淘汰时机"><a href="#2、淘汰时机" class="headerlink" title="2、淘汰时机"></a>2、淘汰时机</h3><p>实际上，每次运行读写命令的时候，都会调用processCommand函数，processCommand中又会调用freeMemoryIfNeeded,这时候就会尝试去释放一定内存，策略就按我们上述配置的策略。</p><p>注意，淘汰的是 key，对应的value 可能很大，所以淘汰一个可能就会腾出比较大的空间</p><h2 id="六、LRU"><a href="#六、LRU" class="headerlink" title="六、LRU"></a>六、LRU</h2><blockquote><p> 只考虑最新版本的</p></blockquote><p>Redis 使用的 LRU 与 正经的 LRU 有区别，它使用的是近似 LRU</p><blockquote><p>因为如果要是所有元素比较，就需要为所有元素维护一个排序的列表，也就是一个双向链表，这样的开销太大，Redis 是内存节约型</p></blockquote><p>首先，并不是在所有的元素中找最近未使用的，也就是活性最低的；而是每次随机取样 5 个（取样有两种选择，使用的淘汰策略是从expires中淘汰则是在设置了过期时间的 </p><p>key 中取样，另一种策略则是在所有的key中取样），在这五个里面选，同时，Redis 还引入了淘汰池进行优化；具体步骤如下：</p><ul><li>先从所有存储对象中随机选取 5 个，加入淘汰池；将活性最低的淘汰掉；</li><li>之后每次选取 5 个，将其中活性小于淘汰池中最低活性的加入到淘汰池；淘汰池大小为16，如果淘汰池满了，则将活性最大的那个移除出去（移除不是淘汰）</li><li>淘汰淘汰池中活性最小的那个</li></ul><p>LRU 使用的是 RedisObject 中的 lru 字段，共 24 位</p><p>为了节省CPU资源，lru字段每 100 ms 才会更新一下</p><p>取样的个数为 n，默认这个n是5；但是 n 为10 时采样的效果最好，最接近原始 LRU 的结果；但是 10 个的话更消耗 CPU</p><h2 id="七、LFU"><a href="#七、LFU" class="headerlink" title="七、LFU"></a>七、LFU</h2><h3 id="1、为什么有了-LRU-还引入-LFU"><a href="#1、为什么有了-LRU-还引入-LFU" class="headerlink" title="1、为什么有了 LRU 还引入 LFU"></a>1、为什么有了 LRU 还引入 LFU</h3><p>因为 LRU 脱离频率，只考虑访问时间；如果有一个对象，之前频繁的访问，快要进行淘汰的时候，另一个几乎没用过的对象被访问了，那么按照 LRU， 频繁访问的这个对象就会被淘汰；这样显然是不好的</p><h3 id="2、LFU"><a href="#2、LFU" class="headerlink" title="2、LFU"></a>2、LFU</h3><p>Redis 使用的 LFU 也是改造过的</p><p>因为 LRU 和 LFU 不可能同时使用，因此 lru 字段就可以复用，节省内存；只不过高16位记录上次访问的时间戳，以分为单位；低8位记录访问的次数；</p><p>Redis 使用的特殊的 LFU，访问次数会随着距离上次访问的时间间隔而逐渐衰减，每分钟减一；</p><p>而它的访问次数加一不是肯定加一；当访问次数小于5时，每次访问次数加一，当次数大于5时，则随机加一，也就是说有可能加，有可能不加； 如果确定加，则很容易就加大最大值 255</p><p>对于那些刚添加的数据，将访问次数设置为5，防止刚添加就被淘汰；</p><p>为什么要设计成大于5次就一定概率加一，而不是一定加一：</p><p>1、避免过度关注热点数据，而将那些非热点数据很快淘汰出去；有概率加一就使得非热点数据得以有机会留在内存中，因为有可能会访问到</p><p>2、给不同的数据项提供相对公平的缓存机会</p>]]></content>
    
    
    <categories>
      
      <category>Redis</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Redis-基本数据类型</title>
    <link href="/Redis/Redis-%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.html"/>
    <url>/Redis/Redis-%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.html</url>
    
    <content type="html"><![CDATA[<h1 id="Redis的几种数据类型"><a href="#Redis的几种数据类型" class="headerlink" title="Redis的几种数据类型"></a>Redis的几种数据类型</h1><p>所有数据类型 key-value 键值对的 key 都是字符串类型</p><h2 id="一、String"><a href="#一、String" class="headerlink" title="一、String"></a>一、String</h2><h3 id="（一）什么是-String"><a href="#（一）什么是-String" class="headerlink" title="（一）什么是 String"></a>（一）什么是 String</h3><p>String 是 Redis 中的基本数据类型，value 为字符串值，既可以为字符串，也可以是转换为字符串的整型、浮点型；String 最大为 512M</p><h3 id="（二）应用场景"><a href="#（二）应用场景" class="headerlink" title="（二）应用场景"></a>（二）应用场景</h3><p>文本数据、字节数据、序列化后的对象….只要是字符串，都可以往里存。</p><ul><li>String 常见的是用于缓存，value 中存储序列化的对象、json字符串、序列化的图片等等</li><li>由于 String 对于整型支持 incr decr，也可以用于计数、统计；而且因为是原子性操作，所以不会有安全风险（因为Redis是单线程处理命令）</li><li>做分布式锁（不要提，防止面试官追问分布式锁相关的东西）</li></ul><h3 id="（三）基础操作"><a href="#（三）基础操作" class="headerlink" title="（三）基础操作"></a>（三）基础操作</h3><ul><li>设置 key-value 类型的值：set key value</li><li>批量设置：mset key1 value1 key2 value2 ….</li><li>不存在才设置 setnx &#x3D;&#x3D; set key value nx</li><li>存在才设置 set key value xx   <strong>注意</strong>：没有 setxx</li><li>设置过期时间：setex key seconds value (单位为s) 等同于 set key value ex seconds</li></ul><p>set key value px milliseconds（单位为ms）  <strong>注意</strong>：没有 setpx</p><ul><li>获取 key 对应的 value：get mget</li><li>获取所有的 key：keys *</li><li>获取 key 存储的字符串值的长度：strlen key</li><li>删除key：del key （会阻塞主线程）   unlink （不会阻塞主线程，适合删除大key）</li><li>针对 int 编码类型的value，可以使用 incr incrby decr decrby</li></ul><p>set 已经存在的 key-value 时，则会覆盖掉旧值以及旧的设定的过期时间</p><h3 id="（四）String底层实现原理"><a href="#（四）String底层实现原理" class="headerlink" title="（四）String底层实现原理"></a>（四）String底层实现原理</h3><h4 id="1、编码格式"><a href="#1、编码格式" class="headerlink" title="1、编码格式"></a>1、编码格式</h4><ol><li>String 存储有三种编码格式，int、embstr、raw</li><li>Embstr 和 raw 都是由 redisObject 和 SDS（Simple Dynamic String）构成</li><li>redisObject 中有 type（4位、encoding（4位）、ptr（64位）、lru （24位）、refcount（32位）       总共16个字节； 不管哪种 sdshdr，这个大小都不会变。</li><li>SDS 中有 len（一个字节，表示已经存储的长度）、alloc（一个字节，表示分配的长度）、flag（一个字节，指示哪种sdshdr）、char[] buf (末尾的 \0 一个字节，buf用于存储数据)，总共四个字节；         针对的是 sdshdr8</li></ol><h5 id="（1）int"><a href="#（1）int" class="headerlink" title="（1）int"></a>（1）int</h5><ul><li>针对在 long 表示范围内的整型，使用 INT 编码格式</li><li>可以使用incr、decr命令；不过只能在 long 范围内，如果超过则报错</li><li>如果存储的不再是整型或者超出long表示的范围或者使用 append 等修改命令，则会转为 raw 编码</li><li>redisObject 中 encoding 为 redis-object-int，整形数据存储在 ptr 字段内，不使用 SDS                    <strong>注意：</strong>因为 ptr 恰好和 long 型一样都是 64位，所以数据存储在 ptr 中是没有问题的；</li></ul><h5 id="（2）embstr"><a href="#（2）embstr" class="headerlink" title="（2）embstr"></a>（2）embstr</h5><ul><li>针对小于等于阈值字节大小的字符串（也叫小字符串）（5.0.5版本的阈值是 44字节），如果超过，则转为 raw（考虑redisObject 和 SDS 头部结构，则整个大小是 44 + 16 + 4 &#x3D; 64字节）</li><li>redisObject 和 SDS 分配在内存上是连续的，只需要一次分配，并且回收时也是一次回收</li><li>redisObject 的 ptr 变量指向SDS</li><li>embstr 设置为只读，如果对其进行修改（比如 append 命令），则先转变为 raw，再修改</li><li>embstr 只读的原因在于，如果一个字符串值进行了修改，则它就被认定为易变的；因为 redisObject 和 SDS 是一同分配的，如果字符串值修改导致 SDS 需要扩容，则连同 redisObject 一起都要重新分配；</li></ul><h5 id="（3）raw"><a href="#（3）raw" class="headerlink" title="（3）raw"></a>（3）raw</h5><ul><li>针对大于阈值（5.0.5 版本为 44）的字符串（也叫大字符串），以及其他由于修改转为 raw 的字符串值</li><li>redisObject 和 SDS 是分两次分配的，回收也需要两次操作；它们在内存上也是不连续的</li><li>如果 SDS 需要扩容，即使需要重新分配，复制到其他地方，redisObject 也是不需要重新分配的，只是 ptr 变化</li></ul><p>为什么是以44字节为界的呢？（针对redis5.0.5版本）</p><p>首先，44字节是 64字节 - 20字节（redisObject 大小）- 4字节（SDS sdshdr8 类型头部结构大小）</p><p>也就是说，问题的本质在于，为什么是以64字节为界。</p><p>主要原因在于，CPU cacheLine 的大小为64字节，如果大小控制在64字节及以内，那么CPU只需要在内存中调取一次，就可以获得所有的数据。这样的话，可以更好地利用局部性原理。</p><h4 id="2、什么是-SDS"><a href="#2、什么是-SDS" class="headerlink" title="2、什么是 SDS"></a>2、什么是 SDS</h4><ul><li>SDS （Simple Dynamic String），简单动态字符串，是针对普通字符串（也就是结尾为 ‘\0’ 的字符数组）的一些缺点提出来的，是对普通字符串的进一步封装。</li><li>SDS 分为 sdshdr5、sdshdr8、sdshdr16、sdshdr32、sdshdr63 五种</li><li>sdshdr5 中只有一个 flag 字段和 buf 数组，flag 的高三位表示sds的类型，低五位用来存放已存储的数据长度</li><li>sdshdr8、16、32、64 都是由 len、malloc、flag、buf[] 组成，len 表示已经存储的数据大小，malloc 表示分配的 buf[] 大小，flag 表示哪种 sds，buf[] 存储数据</li><li>sdshdr8 中的 len 只有8位，因此能表示的最大长度为 2^8 （128）</li></ul><h4 id="3、为什么需要-SDS"><a href="#3、为什么需要-SDS" class="headerlink" title="3、为什么需要 SDS"></a>3、为什么需要 SDS</h4><p>这个问题也可以转变为：为什么字符数组不适合？ 字符数组有什么缺点？（Redis 是C语言写的，字符串是用结尾为 ‘\0’ 的  char 型数组表示的）</p><p>（1）字符数组的缺点：</p><ul><li>获取长度需要遍历一遍，时间复杂度为 O(n)</li><li>扩容比较麻烦，需要重新分配内存然后复制过去</li><li>非二进制安全（字符数组以 \0 作为结束符，\0没法作为普通字符进行存储）</li></ul><p>（2）针对上述缺点，SDS 的解决方案：</p><ul><li>SDS 头部结构中有 len 字段，用于表示已经存储数据的长度，可以直接返回，时间复杂度为 O(1)</li><li>SDS 有预留空间 malloc - len。</li><li>二进制安全，判断字符数组结束不是靠 \0 ，而是 len 字段</li></ul><p>对于预留空间，SDS是这样操作的：当第一次添加字符串值时</p><p>如果添加的字符串值长度 len 小于 1m （1024）字节，则 malloc 分配 len * 2 大小的空间，即预留空间大小为 len；</p><p>如果 len 大于 1m，则分配 len + 1m 大小的空间，即预留空间大小为 1m  </p><p>所以，事实上，预留空间大小为 min（len ， 1m）；</p><p>这样的策略节省空间</p><h2 id="二、Lists"><a href="#二、Lists" class="headerlink" title="二、Lists"></a>二、Lists</h2><h3 id="（一）什么是-Lists"><a href="#（一）什么是-Lists" class="headerlink" title="（一）什么是 Lists"></a>（一）什么是 Lists</h3><p>Lists 也是 Redis 的基本数据类型，key 为字符串，value 是字符串列表，可以从两端进行操作（但不是双向链表），不符合先入先出。有元素个数限制，是 2^32 - 1 ,新版本是 2^64 - 1</p><h3 id="（二）应用场景-1"><a href="#（二）应用场景-1" class="headerlink" title="（二）应用场景"></a>（二）应用场景</h3><p>Lists 可以用来做消息队列，可以用来存储一批任务数据、一批消息等</p><h3 id="（三）基础操作-1"><a href="#（三）基础操作-1" class="headerlink" title="（三）基础操作"></a>（三）基础操作</h3><ul><li>添加：lpush rpush</li><li>弹出：lpop rpop</li><li>范围获取：lrange key begin end             eg：获取所有 lrange key 0 -1  （负数代表倒数第几个）</li><li>删除key：del   unlink</li><li>删除特定的 value： lrem key count value  (删除从左到右count个value等于value的值，如果count为0，则是全部删除)</li><li>获取value列表元素个数：llen key</li></ul><h3 id="（四）底层实现"><a href="#（四）底层实现" class="headerlink" title="（四）底层实现"></a>（四）底层实现</h3><h4 id="1、编码格式-1"><a href="#1、编码格式-1" class="headerlink" title="1、编码格式"></a>1、编码格式</h4><p>3.2版本之前，底层是使用 LinkedList 和 ZipList</p><p>在列表元素个数小于 512 并且列表所有元素小于 64 字节时，使用 ZipList（注：这是List的规定，而不是ZipList的限制）</p><p>其他情况使用 LinkedList</p><h5 id="（1）ZipList"><a href="#（1）ZipList" class="headerlink" title="（1）ZipList"></a>（1）ZipList</h5><ul><li>ZipList 底层是压缩列表，列表的对象元素紧挨在一起，在元素之前，有 zllen；在之后有zlend；   </li><li>每一个元素是一个entry，其中有 prevlen 字段，表示前一个对象元素的长度，因此 ZipList 有了从后往前遍历的能力。</li></ul><h5 id="（2）LinkedList"><a href="#（2）LinkedList" class="headerlink" title="（2）LinkedList"></a>（2）LinkedList</h5><ul><li>LinkedList 底层是双向链表，不是连续分布的</li><li>LinkedList 的表头结构中，有一个 len 字段，表示链表中的节点数量。因此获取节点元素个数的时间复杂度为 O(1)</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">list</span> &#123;<br>    listNode*head;<br>    listNode *tail;<br>    <span class="hljs-type">void</span> *(*dup)(<span class="hljs-type">void</span> *ptr);<br>    <span class="hljs-built_in">void</span> (*free)(<span class="hljs-type">void</span> *ptr);<br>    <span class="hljs-built_in">int</span> (*match)(<span class="hljs-type">void</span> *ptr, <span class="hljs-type">void</span> *key);<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> len;   <span class="hljs-comment">//长度字段</span><br>&#125; list;<br></code></pre></td></tr></table></figure><p>二者相比：</p><p>ZipList 对象元素紧凑存储，内存碎片产生少，并且没有链表节点指针的空间消耗；而 LinkedList 插入的效率比较高</p><p>对于对象元素数量多的，应该采用 LinkedList，因为ZipList 的对象元素是紧挨着的，插入一个对象元素后续的对象元素都要移动，时间复杂度为 O(n)，而 LinkedList 插入的时间复杂度为 O(1)</p><p>对于对象元素大的，也应该采用 LinkedList，因为ZipList 的元素对象是紧挨着的，如果插入新的对象元素，由于后续的对象元素都很大，移动的效率会很低</p><p>LinkedList 和 ZipList 查询一个对象元素的时间复杂度都是 O(n)</p><p>在3.2版本以后，使用了 QuickList </p><h5 id="（3）QuickList"><a href="#（3）QuickList" class="headerlink" title="（3）QuickList"></a>（3）QuickList</h5><p>QuickList 是将 ZipList 和 LinkedList 的优点结合起来的新的编码格式，QuickList 有两个指针，指向多个 QuickListNode 连接成的链表的头和尾，而每个 QuickListNode 存储一个 ZipList</p><p>QuickList 是压缩列表组成的双向链表</p><h3 id="（五）底层数据结构压缩列表"><a href="#（五）底层数据结构压缩列表" class="headerlink" title="（五）底层数据结构压缩列表"></a>（五）底层数据结构压缩列表</h3><h4 id="1、什么是压缩列表"><a href="#1、什么是压缩列表" class="headerlink" title="1、什么是压缩列表"></a>1、什么是压缩列表</h4><p>从名称就可以看出，（就是排列紧凑的列表）是一种内存紧凑存储元素的数据结构，内存上连续分布，节省内存空间，不易产生空间碎片，也没有链表指针的空间开销；并且，由于内存上连续，CPU使用缓存命中率高（空间局部性会好一些）</p><p>压缩列表在 Redis 中有两种编码格式，ZIPLIST 和 LISTPACK，一般说的压缩列表就是指 ZIPLIST，LISTPACK 是 5.0 引入，直到7.0才完全替代 ZIPLIST</p><h4 id="2、压缩列表解决什么问题"><a href="#2、压缩列表解决什么问题" class="headerlink" title="2、压缩列表解决什么问题"></a>2、压缩列表解决什么问题</h4><p>节省内存空间（节省链表指针的开销）、小数据量时，遍历访问性能更好（顺序连续存储、缓存命中率好）</p><p>缓存命中率体现在是顺序存储，数据可以一次性从内存调入CPU中（空间局部性）</p><h4 id="3、ZIPLIST-的整体结构"><a href="#3、ZIPLIST-的整体结构" class="headerlink" title="3、ZIPLIST 的整体结构"></a>3、ZIPLIST 的整体结构</h4><p>ZIPLIST 的整体结构从前往后是 zlbytes、zltail、zllen、entry1、entry2…. zlend</p><ul><li>zlbytes：表示整个 ZIPLIST 的字节大小，包含 zlbytes 本身</li><li>zltail：表示从 ZIPLIST 开始到最后一个 entry 的距离，zlbytes &#x3D; zltail + 最后一个 entry 的长度 + zlend 长度（一个字节）；</li></ul><p>可以通过 zltail 和 ZIPLIST 的起始地址定位到最后一个 entry ； 如果是一个空的 ZIPLIST，则 zltail 定位到的是 zlend</p><ul><li>zllen：表示 entry 的个数</li><li>zlend：一个特殊的 entry ；表示 ZIPLIST 的结尾，是用一个全一字节 11111111 表示</li><li>entry：存储的对象元素</li></ul><h4 id="4、ZIPLIST-的节点结构（entry）"><a href="#4、ZIPLIST-的节点结构（entry）" class="headerlink" title="4、ZIPLIST 的节点结构（entry）"></a>4、ZIPLIST 的节点结构（entry）</h4><p>entry 由三部分构成，从前往后是 prevlen、encoding、entry-data</p><ul><li><p>prevlen：表示前一个 entry 的长度，通过这个字段，可以定位到上一个 entry 的开始，ZIPLIST 才有了从后往前遍历的能力；prevlen 默认是一个字节，但是当前一个元素的大小超过 254 （2^8 - 1）时（不能是 255，因为 11111111 是结尾标志，不能使用），prevlen 就会变为5个字节，最高字节是 11111110（254），用于标识该prevlen为5字节的，剩下的字节表示上一个 entry 的长度。 <strong>因为这个</strong>，导致了ZIPLIST 最主要的问题——连锁更新</p></li><li><p>encoding：encoding 是一个整型字段，encoding 用来表示 entry-data 的数据类型以及长度，一般是高几位代表类型，低位代表长度；但是对于 int 类型，每一种encoding代表一种特定长度的int； 特别的，对于 1111**** 这个编码，除了 11111111（代表结束）和 11111110（代编8个字节的INT64），其他的就表示特定的 INT 类型的数，比如 11110001 就代表 1，此时 entry-data 就没有了；                 <strong>因为有了 encoding 表示 entry-data 的长度，才使得 ZIPLIST 有了从前往后遍历的能力</strong></p></li><li><p>entry-data：存放的实际数据</p></li></ul><p>根据 encoding 表示 entry-data 的类型和长度，使得有了从前往后遍历的能力，这是因为，entry 的三个部分中，prevlen 可以通过最高字节是否是 11111110 判断出是一个字节还是五个字节长；encoding 可以根据最高几位得出 encoding 的长度，比如最高位为 00 ，则代表 encoding 是一个字节长；entry-data 的长度可以由 encoding 获得；因此，虽然只有 entry-data 的长度是可以直接获得的，但是整个 entry 的长度也是可以确定的。</p><h4 id="5、ZIPLIST-查询数据"><a href="#5、ZIPLIST-查询数据" class="headerlink" title="5、ZIPLIST 查询数据"></a>5、ZIPLIST 查询数据</h4><ul><li>查询 ZIPLIST 的数据总量：通常情况下，直接通过 zllen 就可以获得 entry 的个数，时间复杂度为 O(1)； 为什么是通常情况呢，因为 zllen 只有两个字节，最大可以表示 11111110 （11111111 表示结尾），即 65534 个entry，如果 entry 个数超过 65534，则 zllen 会置为0，提示需要遍历才能得出长度，此时时间复杂度为 O(n)</li><li>在 ZIPLIST 中查询指定数据的节点：需要遍历，时间复杂度为 O(n)</li></ul><h4 id="6、ZIPLIST-更新数据"><a href="#6、ZIPLIST-更新数据" class="headerlink" title="6、ZIPLIST 更新数据"></a>6、ZIPLIST 更新数据</h4><p>ZIPLIST 更新数据是比较消耗资源的，因为底层是压缩列表，插入一个对象元素时，后边的都需要移动，尤其是对象元素数量多 或者 对象元素普遍比较大的情况。尾部插入就不需要移动；综合起来，时间复杂度还是为 O(n)</p><p>并且，ZIPLIST 存在一个最主要的问题——连锁更新。</p><p>连锁更新是指，当某个 entryA 前插入一个大于 254 字节的 newentry 时，entryA 的 prevlen 就要从一个字节变为五个字节， 而如果 entryA 的总长度因为 prevlen 的变化超过了 254 字节时，后边的 entryC 的 prevlen 又会从一个字节变为五个字节….. 如此下去，则后续很多 entry 都要发生变化，而每一次 entry 的变化，都会使后续的都发生移动</p><p>虽然连锁更新的概率很小，但是还是 ZIPLIST 的最主要的问题，主要是因为会导致性能不稳定；连锁更新的时间复杂度为 O(n^2)</p><h4 id="7、LISTPACK-优化"><a href="#7、LISTPACK-优化" class="headerlink" title="7、LISTPACK 优化"></a>7、LISTPACK 优化</h4><p>连锁更新的原因就在于：由于需要从后往前遍历的能力，所以有了 prevlen 字段，因为这个字段长度的变化，才导致了连锁更新问题的发生。要解决连锁更新问题，就要对 entry 的结构进行改变。</p><p>LISTPACK 采取的优化办法是，改变 entry 的结构。分为三部分：encoding-type、element-data、element-tot-len。重点就在于 element-tot-len</p><h5 id="element-tot-len"><a href="#element-tot-len" class="headerlink" title="element-tot-len"></a>element-tot-len</h5><p>这个字段表示当前 encoding-type + element-data 的长度（取消了 ZIPLIST 中表示上一个 entry 长度的 prevlen），由于该字段只是表示当前 entry 一部分的长度，所以前面插入大的 entry 也是没有影响的。</p><p>element-tot-len 采用了一种比较巧妙地方式，它是从后往前扫描，每个字节的高位是标识 element-tot-len 是否结束的标志。为 1 代表整个字节不是结束，需要继续往前扫描，如果是 0 则代表这是最后一个字节，停止扫描。最终所有的字节去掉最高位合并起来就是正确的长度</p><p>利用这样的方式，encoding-type + element-data 的长度无论是多大，都可以用 element-tot-len 表示。</p><p>比如说 element-tot-len 为 00001000 10001100 ，从后往前第一个字节为 10001100，最高位为1，代表继续扫描。第二个字节为 00001000，最高位为0，停止扫描；两个字节都去掉最高位，则最终的结果是 0001000 0001100 ，代表 1024 + 4 + 8 &#x3D; 1036</p><h3 id="（六）面试题"><a href="#（六）面试题" class="headerlink" title="（六）面试题"></a>（六）面试题</h3><p>1、ZIPLIST 的优点（可以与 LinkedList 比较着说）</p><p>节省内存（避免链表节点指针的开销），产生空间碎片概率小、一次性分配内存（因为是连续的，因此一次性分配就可以，而 LinkedList 需要多个节点多次分配）、空间局部型好（小数据量遍历时性能更好，缓存命中率高）</p><p>2、QUICKLIST的设计是怎样的</p><p>为了应对ziplist的问题，在3.2版本实现的quicklist在ziplist的基础上，通过链表将ziplist串联起来，每一个链表元素都是一个ziplist,这样就可以减少新增ziplist时的内存分配，而且quicklist限制了ziplist的大小，当一个ziplist大小过大，就会新增一个quicklist节点</p><p>3、为什么又出现了LISTPACK的设计</p><p>虽然quicklist的调和了ziplist和linklist的一些优缺点，但是由于quicklist使用quicklistNode指针ziplist,也会增加较大的内存开销，所以，又实现出了listpack结构，listpack延续ziplist的紧凑型结构，但是区别的是listpack中的每一个节点不会记录前一个节点的长度，可以避免连锁更新问题</p><h2 id="三、Set"><a href="#三、Set" class="headerlink" title="三、Set"></a>三、Set</h2><h3 id="（一）什么是-set"><a href="#（一）什么是-set" class="headerlink" title="（一）什么是 set"></a>（一）什么是 set</h3><p>set 就是一系列对象元素的无序、不重复集合；</p><h3 id="（二）set-的应用场景"><a href="#（二）set-的应用场景" class="headerlink" title="（二）set 的应用场景"></a>（二）set 的应用场景</h3><p>适用于无序、不重复的场景，比如某个用户关注的博主、公众号之类的，这些信息可以放进一个集合；并且set 因为有并交叉运算，可以轻松获得用户之间的共同关注之类的信息</p><h3 id="（三）常用操作"><a href="#（三）常用操作" class="headerlink" title="（三）常用操作"></a>（三）常用操作</h3><p>创建新的set、向set中添加对象元素： sadd</p><p>获取所有对象元素：smenbers</p><p>获取set 对象元素个数：scard</p><p>删除对象元素：srem key member1， member2 …..</p><p>判断是否是 set 中的：sismember</p><p>获取范围内：sscan key cursor [match patten] [count n]     <strong>注意：</strong>  对intset编码的没用</p><p>交并差：sinter key1 key2 key3 …    sunion key1 key2 key3…     sdiff key1 key2 key3…</p><h3 id="（四）底层实现-1"><a href="#（四）底层实现-1" class="headerlink" title="（四）底层实现"></a>（四）底层实现</h3><p>set 出于性能和内存的双重考虑，底层有两种编码格式，intset 和 hashtable</p><p>对于元素都是整型，并且个数少于 512 的，采用 intset，其他采用 hashtable</p><h4 id="1、intset"><a href="#1、intset" class="headerlink" title="1、intset"></a>1、intset</h4><p>intset 是内存连续的，查找 member 时，使用二分查找，也就是说，它其实是有序的</p><h4 id="2、hashtable"><a href="#2、hashtable" class="headerlink" title="2、hashtable"></a>2、hashtable</h4><p>hashtable 的 key 用来存储元素，value 都为 null，因此，hashtable 查找元素的时间复杂度为 O(1)</p><h2 id="四、Hash"><a href="#四、Hash" class="headerlink" title="四、Hash"></a>四、Hash</h2><h3 id="（一）什么是-Hash"><a href="#（一）什么是-Hash" class="headerlink" title="（一）什么是 Hash"></a>（一）什么是 Hash</h3><p>Hash 是 Redis 中的基本数据类型，它是 field 和 value 都是字符串的 hash 表；Redis 中每个 hash 最多可以存储 2^32 - 1 对键值对</p><h3 id="（二）Hash-的应用场景"><a href="#（二）Hash-的应用场景" class="headerlink" title="（二）Hash 的应用场景"></a>（二）Hash 的应用场景</h3><p>适合 O(1) 查找某个 filed 对应 value 的场景，适合 key&#x2F;value 形式的数据存储</p><p>Hash可以用来存储一些类似一对一对配置信息的数据（类似 json）</p><h3 id="（三）Hash-常用操作"><a href="#（三）Hash-常用操作" class="headerlink" title="（三）Hash 常用操作"></a>（三）Hash 常用操作</h3><p>新建hash、添加：hset key field1 value1 filed2 value2 …..     、 hsetnx</p><p>获取 hash 中 filed 对应的 value ： hget key filed</p><p>获取所有的 filed 和 value：hgetall</p><p>获取 hash 对的个数：hlen key</p><p>获取 hash 对：hscan       <strong>注意</strong> *scan 类型的命令对于 ZIPLIST、INTSET 等内存连续型是无效的</p><p>删除 hash 对：hdel key filed1 filed2 filed3……</p><p>删除hash ：del 、unlink</p><h3 id="（四）底层实现-2"><a href="#（四）底层实现-2" class="headerlink" title="（四）底层实现"></a>（四）底层实现</h3><p>Hash 底层有两种实现编码 ZipList（在7.0之后被 ListPack 替代）和  HashTable</p><ul><li>当 hash 对的 filed 和 value 都小于 64 字节并且 filed 数量少于 512 时，使用 ZipList（跟 List 类似）</li><li>其他情况使用 HashTable</li></ul><h4 id="1、ZipList"><a href="#1、ZipList" class="headerlink" title="1、ZipList"></a>1、ZipList</h4><p>hash 对的 filed 和 value 单独作为 entry 存储，整个 ZipList 在内存上连续。</p><h4 id="2、HashTable"><a href="#2、HashTable" class="headerlink" title="2、HashTable"></a>2、HashTable</h4><p>跟 set 不同的是，hash 的底层 hashtable 的 value 不为 null，而是存的 hash 对的 value。</p><h2 id="五、HashTable"><a href="#五、HashTable" class="headerlink" title="五、HashTable"></a>五、HashTable</h2><p>HashTable 扮演着快速索引的角色，可以使用 O(1) 的时间复杂度查询到 key 对应的 value</p><h3 id="（一）HashTable-的结构"><a href="#（一）HashTable-的结构" class="headerlink" title="（一）HashTable 的结构"></a>（一）HashTable 的结构</h3><p>HashTable 实现是 dictht 对象，内部有 size、sizemask、used、table 数组</p><ul><li>size：HashTable 的存储空间</li><li>sizemask：哈希掩码，用于与哈希值按位相与获得存储的位置；等于 size - 1；</li><li>used：实际存储的键值对的数量</li><li>Table 数组：存储实际数据；数组的每一个元素是一个 bucket，用于存储一串哈希值相同的键值对；（也就是解决哈希冲突采用拉链法）</li></ul><h3 id="（二）哈希表渐进式扩容-缩容"><a href="#（二）哈希表渐进式扩容-缩容" class="headerlink" title="（二）哈希表渐进式扩容&#x2F;缩容"></a>（二）哈希表渐进式扩容&#x2F;缩容</h3><p>为什么要扩容缩容呢？</p><p>当数据存储的越来越多，哈希冲突概率越来越大，链表长度变长，此时的查询效率就不再是 O(1),而是O(n)，n 为链表的长度；此时就需要扩容</p><p>当数据存储的很少时，为节省空间，就进行缩容</p><p>一般扩容&#x2F;缩容的操作是，新分配一块内存，然后将数据一次性迁移过去；这样就造成了一个问题：数据量很大的时候，迁移是非常耗时的，会导致服务器在一段时间内停止服务；为解决这个问题，就提出了渐进式扩容；</p><p>首先，在 dictht 上又封装了一层 dict，也就是常说的字典（Redis 存储数据就是使用的字典）；dict 的构造：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs Java">typedef struct dict &#123;<br>    dictType *type;<br>    <span class="hljs-keyword">void</span> *privdata;<br>    dictht ht[<span class="hljs-number">2</span>];<br>    <span class="hljs-type">long</span> rehashidx; <br>    unsigned <span class="hljs-type">long</span> iterators；<br>&#125; dict;<br></code></pre></td></tr></table></figure><ul><li>type：指向 dictType 的指针，保存了一系列特定函数，比如计算 hash 值的 hashFunction() </li><li>ht[2]：ht[0] 是当前存储数据的 dictht； ht[1] 是扩容或缩容时新分配内存的 dictht</li><li>rehashidx：是迁移时的索引，指向当前要迁移的数据；为 0 代表扩容开始；为 -1 代表完成</li></ul><p>当要扩容&#x2F;缩容时，首先给 ht[1] 分配内存：</p><p>扩容时，分配的内存大小为大于等于 ht[0] 的 used * 2 的第一个二次方幂；</p><p>缩容时，为大于等于 used 的第一个二次方幂；</p><p>分配完内存，将 rehashidx 置为0，代表扩容开始；每发生一次增删改查，就将 rehashidx 指向的数据迁移到 ht[1] 中；直到所有的数据迁移完成，释放 ht[0] 的空间，ht[1] 和 ht[0] 的指针交换，将 ht[1] 又指向空的哈希表；最后将 rehashidx 置为 -1，代表完成</p><p> 注意，扩容或者缩容开始后，ht[0] 这个表数据只会少，不会多；</p><p>新增数据时，只会新增到 ht[1] ；删除、修改、查找数据时，在 ht[0]、ht[1] 都要查找，找到进行操作；</p><blockquote><p>在迁移过程中，rehashidx 指向的可能为空（此处数据之前可能被删了），此时并不是直接返回，而是继续往下搜索，如果连续10个都为空，则返回；</p></blockquote><h3 id="（二）哈希表扩容-缩容时机"><a href="#（二）哈希表扩容-缩容时机" class="headerlink" title="（二）哈希表扩容&#x2F;缩容时机"></a>（二）哈希表扩容&#x2F;缩容时机</h3><p>扩容缩容跟负载因子有关；负载因子 &#x3D; used &#x2F; size</p><ul><li>当负载因子大于 1 小于 5时，如果此时服务器有 BGSAVE 、BGREWRITEAOF 命令执行，则不扩容；如果没有这些命令执行，则扩容</li><li>当负载因子大于 5 时，不管有没有命令执行，都扩容</li><li>当负载因子小于 0.1 并且没有上述命令执行时，缩容</li></ul><h2 id="六、跳表"><a href="#六、跳表" class="headerlink" title="六、跳表"></a>六、跳表</h2><h3 id="（一）什么是跳表"><a href="#（一）什么是跳表" class="headerlink" title="（一）什么是跳表"></a>（一）什么是跳表</h3><p>跳表也是链表，只不过是多级索引的链表，通过多级索引，就可以实现一次性跨越多个节点；可以将普通链表 O(n) 的操作时间复杂度降为 O(logn)</p><h3 id="（二）跳表的结构"><a href="#（二）跳表的结构" class="headerlink" title="（二）跳表的结构"></a>（二）跳表的结构</h3><p>跳表的结构：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs Java">typedef struct zskiplist &#123;<br>    struct zskiplistNode *header, *tail;<br>    unsigned <span class="hljs-type">long</span> length;<br>    <span class="hljs-type">int</span> level;<br>&#125; zskiplist;<br></code></pre></td></tr></table></figure><ul><li>header、tail 为头尾节点</li><li>length 代表节点个数</li><li>level 代表最大有几层索引</li></ul><p>跳表节点的结构：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs Java">typedef struct zskiplistNode &#123;<br>    <span class="hljs-comment">//Zset对象的元素值</span><br>    sds ele ;<br>    <span class="hljs-comment">//元素权重值</span><br>    <span class="hljs-type">double</span> score;<br>    <span class="hljs-comment">//后向指针</span><br>    struct zskiplistNode *backward;<br>    <span class="hljs-comment">//节点的level数组，保存每层上的前向指针和跨度</span><br>    struct zskiplistLevel &#123;<br>        struct zskiplistNode *forward;<br>        unsigned <span class="hljs-type">long</span> span;<br>    &#125; level[];<br>&#125; zskiplistNode; <br></code></pre></td></tr></table></figure><p>sds：Simple Dynamic String，存放数据的，之前学过</p><p>score：分值，就是按照这个字段对数据进行排序</p><p>backward:  从后向前的指针，一个节点只有一个，这个指针是针对第一层的，其他层没有后向指针；</p><p>level 数组：数组有几个元素代表有几层索引，每一个元素的 forward 存放的是指向该层下一个节点的指针，span 是到该层下一个节点实际跨越的距离; 在zset 使用跳表作为编码时，zrank 命令就使用了 span</p><p>当 zset 使用跳表作为编码方式的时候，zrevrange 命令就是依靠的 backward 字段</p><h3 id="（三）节点的索引层数"><a href="#（三）节点的索引层数" class="headerlink" title="（三）节点的索引层数"></a>（三）节点的索引层数</h3><p>节点的索引层数是随机的，每一个节点在新建的时候就随机确定了层数；初始都为一层，每加一层的概率是 0.25，也就是说第一层每四个有一个进入第二层；第二层每四个进入第三层……</p><p>层数具有最大限制，目前使用的版本 5.0 限制是 64</p><h2 id="七、ZSet"><a href="#七、ZSet" class="headerlink" title="七、ZSet"></a>七、ZSet</h2><h3 id="（一）什么是-ZSet"><a href="#（一）什么是-ZSet" class="headerlink" title="（一）什么是 ZSet"></a>（一）什么是 ZSet</h3><p>Zset 是一种有序、不重复集合，是一组按照关联分数（score）排序的字符串集合；这里的分数可以由任何指标计算得来</p><h3 id="（二）ZSet-使用场景"><a href="#（二）ZSet-使用场景" class="headerlink" title="（二）ZSet 使用场景"></a>（二）ZSet 使用场景</h3><p>有序的场景，比如点赞榜、积分榜、优先度排行等</p><h3 id="（三）常用操作-1"><a href="#（三）常用操作-1" class="headerlink" title="（三）常用操作"></a>（三）常用操作</h3><p>添加修改：zadd key score member …. 、zrem key member …  (zadd 可以搭配 nx、xx、lt、bt 等参数)</p><p>zcard key：查询 member 个数</p><p>zcount key min max： 查询分数在 min max 之间的元素个数</p><p>zrange key begin end （withscores）：查询位置范围内的 member ，如果由 withscore 选项，则连同分数一块查出</p><p>zrevrange key begin end（withscores）：反向查找</p><p>zrank key member：查询 member 的排名，从 0 开始</p><p>zscore key member ：查询member 的分数 </p><h3 id="（四）底层实现-3"><a href="#（四）底层实现-3" class="headerlink" title="（四）底层实现"></a>（四）底层实现</h3><p>ZSet 的底层实现有两种，压缩列表和跳表</p><ul><li>当member 数量少于 128，并且每个 member 小于 64 字节时，使用压缩列表</li><li>其他情况使用跳表 skiplist + hashtable</li></ul><h4 id="1、压缩列表"><a href="#1、压缩列表" class="headerlink" title="1、压缩列表"></a>1、压缩列表</h4><p>5.0版本使用的还是 ziplist</p><h4 id="2、skiplist-hashtable"><a href="#2、skiplist-hashtable" class="headerlink" title="2、skiplist + hashtable"></a>2、skiplist + hashtable</h4><p>使用 skiplist 存储 member（sds） 和 score（score 字段）</p><p>hashtable 存储 key 为 member，value 为 score；（hashtable 的唯一作用就是 zscore 命令，复杂度为 O(1) ）  </p>]]></content>
    
    
    <categories>
      
      <category>Redis</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>进程管理</title>
    <link href="/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86.html"/>
    <url>/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86.html</url>
    
    <content type="html"><![CDATA[<h1 id="1、进程、线程基础知识"><a href="#1、进程、线程基础知识" class="headerlink" title="1、进程、线程基础知识"></a>1、进程、线程基础知识</h1><h2 id="1-1-进程"><a href="#1-1-进程" class="headerlink" title="1.1 进程"></a>1.1 进程</h2><h3 id="1-1-1-进程的状态"><a href="#1-1-1-进程的状态" class="headerlink" title="1.1.1 进程的状态"></a>1.1.1 进程的状态</h3><p>进程的状态有 创建、就绪、运行、阻塞、就绪挂起、阻塞挂起、结束 七种状态。</p><ul><li>创建：进程创建过程中的状态，创建成功后转变为就绪状态</li><li>就绪：等待CPU运行时的状态</li><li>运行：在CPU上运行时的状态</li><li>阻塞：运行时的进程，需要等待某些事件发生，例如 IO 操作，就会暂时停止运行；转为阻塞状态，等待条件完成后，就转为就绪状态</li><li>因为内存不存，被换出到磁盘上，称之为挂起。等再次需要运行的时候，再换入到内存中</li><li>进程终止过程中的状态，称为结束状态</li></ul><p>状态之间的转换关系：</p><p>创建 -》就绪    &#x3D;&#x3D;创建 -》就绪挂起&#x3D;&#x3D;    就绪 -&gt;》运行    就绪 -》就绪挂起    运行 -》就绪    运行 -》阻塞     运行 -》就绪挂起    运行 -》结束    阻塞 -》就绪    阻塞 -》阻塞挂起    就绪挂起 -》就绪    阻塞挂起 -》就绪挂起    阻塞挂起 -》阻塞    </p><img src="http://yolo-img.oss-cn-beijing.aliyuncs.com/img/image-20231114205950041.png" alt="image-20231114205950041" style="zoom: 67%;" /><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/11-PCB%E5%AB%96%E5%A8%BC.jpg" alt="知乎搜 PCB 的提示"></p><h3 id="1-1-2-进程的控制结构"><a href="#1-1-2-进程的控制结构" class="headerlink" title="1.1.2 进程的控制结构"></a>1.1.2 进程的控制结构</h3><p>PCB（Process Control Block）进程控制块，&#x3D;&#x3D;是进程的唯一标识&#x3D;&#x3D;，PCB随着进程的创建而创建，随着进程的结束而消失</p><p>PCB 中记录了：</p><ul><li>进程描述信息：pid、用户标识（进程属于哪个用户）</li><li>进程控制和管理信息：进程状态、&#x3D;&#x3D;进程优先级&#x3D;&#x3D;</li><li>进程资源分配清单：有关内存地址和虚拟地址空间的信息，打开的文件以及使用的 I&#x2F;O 设备等信息</li><li>CPU相关信息：保存了该进程在 CPU 中的上下文信息，即 CPU 寄存器等信息</li><li>其他进程的PCB链接：PCB 一般使用&#x3D;&#x3D;链表&#x3D;&#x3D;进行管理，需要存储下一个PCB节点的地址信息</li></ul><p>PCB有两种组织结构：链表和索引，因为进程创建、销毁比较频繁，所以采用链表方式。</p><p>将同状态的进程的PCB使用链表链接起来。</p><img src="http://yolo-img.oss-cn-beijing.aliyuncs.com/img/image-20231114213031737.png" alt="image-20231114213031737" style="zoom: 67%;" /><h3 id="1-1-3-进程的控制"><a href="#1-1-3-进程的控制" class="headerlink" title="1.1.3 进程的控制"></a>1.1.3 进程的控制</h3><p>1、创建进程</p><p>操作系统允许一个进程创建另一个进程，并且运行子进程继承父进程所拥有的资源（虚拟地址空间一样）</p><p>创建过程：</p><ul><li>创建一张空白PCB，向其中填写一些控制和管理信息，比如 pid、用户标识符等</li><li>为该进程分配运行所必须的资源，比如内存资源</li><li>将PCB插入到就绪队列，等待被调度</li></ul><p>2、终止进程</p><p>终止进程有三种方式：进程执行完正常终止、进程异常终止、外界干预（kill 命令）</p><p>&#x3D;&#x3D;当子进程被终止时，在父进程处继承的资源要归还给父进程；当父进程终止时，该父进程的子进程作为孤儿进程被一号进程托管，由一号进程负责完成状态收集工作&#x3D;&#x3D;</p><p>终止过程：</p><ul><li>查找需要终止的进程的PCB</li><li>如果处于运行状态，就立即终止运行</li><li>如果还有子进程，将子进程交给一号进程接管</li><li>将所有的资源归还给操作系统</li><li>将PCB从所在队列中删除</li></ul><p>3、阻塞进程</p><p>进程的阻塞是主动过程，而阻塞的进程被唤醒是被动的，只能由另一个进程唤醒</p><p>阻塞过程：</p><ul><li>查找需要阻塞的进程的PCB</li><li>停止进程运行，保护现场，释放CPU资源</li><li>将PCB中的进程状态改变为阻塞，将其从运行队列中转移至阻塞队列</li></ul><p>4、唤醒进程</p><p>&#x3D;&#x3D;阻塞的进程不可能自己唤醒自己&#x3D;&#x3D;</p><p>唤醒过程：</p><ul><li>在阻塞队列中找到需要唤醒的进程的PCB</li><li>修改PCB中的进程状态为就绪</li><li>将PCB从阻塞队列中删除，添加到就绪队列中</li></ul><h3 id="1-1-4-进程的上下文切换"><a href="#1-1-4-进程的上下文切换" class="headerlink" title="1.1.4 进程的上下文切换"></a>1.1.4 进程的上下文切换</h3><p><code>进程是由内核进行管理和调度的，因此进程的上下文切换一定发生在内核态</code></p><p>进程在 CPU 中运行时，会有一系列信息，包含进程的用户空间资源（虚拟内存、栈、全局变量等）、内核空间资源（内核堆栈、寄存器等），这些信息在进程离开CPU或者进入CPU时，都是需要保存下来或者恢复的，这就叫进程的上下文（&#x3D;&#x3D;上下文就是进程运行时的环境&#x3D;&#x3D;）切换。这些信息都存储在PCB中。</p><p>（简单说，就是把进程在CPU中运行时，CPU中所有与该进程有关的信息保存下来）</p><h3 id="1-1-5-进程的组成"><a href="#1-1-5-进程的组成" class="headerlink" title="1.1.5 进程的组成"></a>1.1.5 进程的组成</h3><p>进程由 PCB、程序段、数据段组成</p><p>PCB 是给操作系统用的，用来管理进程；而程序段和数据段是给进程自己用的；</p><h2 id="1-2-线程"><a href="#1-2-线程" class="headerlink" title="1.2 线程"></a>1.2 线程</h2><h3 id="1-2-1-为什么使用线程"><a href="#1-2-1-为什么使用线程" class="headerlink" title="1.2.1 为什么使用线程"></a>1.2.1 为什么使用线程</h3><p>（问题可以理解为：有了进程为什么还需要线程）</p><p>进程的缺点：</p><ul><li>通信、共享数据困难；</li><li>维护进程的开销大。创建时，创建PCB，分配内存；终止时，回收资源；切换时，保存进程状态信息</li></ul><p>因为这些缺点，线程才出现了。</p><p>没有线程时，进程是资源分配和调度的单位，创建或者撤销进程时，系统都要分配&#x2F;回收资源，如内存空间、I&#x2F;O设备等，需要较大的时空开销，限制了并发程度的提高。所以，将进程的&#x3D;&#x3D;资源分配&#x3D;&#x3D;和&#x3D;&#x3D;调度&#x3D;&#x3D;这两个属性分开处理，资源分配还是进程，但是调度改为线程，把调度执行与切换的责任交给线程</p><p>&#x3D;&#x3D;引入线程前，进程是资源分配和独立调度的基本单位。引入线程后，<strong>进程是资源分配的基本单位，线程是独立调度的基本单位</strong>。&#x3D;&#x3D;</p><h3 id="1-2-2-什么是线程"><a href="#1-2-2-什么是线程" class="headerlink" title="1.2.2 什么是线程"></a>1.2.2 什么是线程</h3><p>&#x3D;&#x3D;线程是进程中的一条执行流程&#x3D;&#x3D;</p><p>同一个进程中的线程可以共享代码段、数据段、文件等资源，但每个线程又有自己的一套独立的栈和寄存器（程序计数器），这样可以确保线程的控制流是相对独立的。</p><img src="http://yolo-img.oss-cn-beijing.aliyuncs.com/img/image-20231114223939715.png" alt="image-20231114223939715" style="zoom: 50%;" /><p>线程的优点：</p><ul><li>一个进程中可以存在多个线程</li><li>维护线程的开销小</li><li>同一个进程中的线程之间，可以方便的进行通信、共享数据</li></ul><p>线程的缺点： </p><ul><li>&#x3D;&#x3D;一个线程崩溃，所属进程的所有线程都崩溃&#x3D;&#x3D;。（因为进程中的所有线程是共享一些资源的，某一个线程出现问题，可能会使共享的资源产生错误，为了避免其他线程纷纷出现错误，让所有的线程全都崩溃是安全选择）</li><li>Java 是个特例，某个线程崩溃，所属进程不会崩溃</li><li>因为这个缺点，对于游戏的用户设计，就不能使用多线程，否则一个挂了，同属一个进程的所有线程都会挂掉</li></ul><h3 id="1-2-3-进程和线程的比较"><a href="#1-2-3-进程和线程的比较" class="headerlink" title="1.2.3 进程和线程的比较"></a>1.2.3 进程和线程的比较</h3><p>异：</p><ul><li>进程是资源分配（内存、打开的文件等）的单位，线程是 CPU 调度的单位</li><li>进程维护的开销大，线程维护的开销小（从创建、切换、销毁等方面）</li><li>进程间共享数据、通信困难麻烦，同一个进程的线程之间通信较为简便</li><li>进程拥有完整的资源平台，线程只独享必不可少的资源（栈、寄存器），共享代码段、数据段、文件等资源</li></ul><p>同：</p><ul><li>进程有就绪、运行、阻塞等状态，线程同样也有</li><li>进程有 PCB，线程有 TCB</li></ul><p>&#x3D;&#x3D;线程相比进程能减少开销&#x3D;&#x3D;，体现在：</p><ol><li>线程创建所需时间更短。进程创建时还需要各种资源管理信息，比如内存管理信息、文件管理信息等。而线程创建时就不需要，线程只需要一些必要的信息就可以，各种资源信息直接共享。</li><li>线程终止时间也更短，因为不需要释放那么多的资源</li><li>线程切换更快，因为需要维护的上下文信息没有那么多，线程共享虚拟内存空间，所以在切换时，就不用切换页表等。而进程需要切换页表</li><li>同一进程的所有线程之间，共享内存空间和文件资源，在线程之间通信、共享数据时，就不用通过内核，效率就会极大提升</li></ol>]]></content>
    
    
    <categories>
      
      <category>操作系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
